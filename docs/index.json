[{"uri":"/01introduction/keybert.html","title":"1.1 KeyBert","tags":[],"description":"","content":"使用场景 KeyBERT是一种小型且容易上手使用的关键字提取技术，它利用BERT嵌入来创建与文档最相似的关键词和关键字短语。\n尽管我们已经有许多可用于关键字生成的方法(例如，Rake、YAKE!、TF-IDF等)，但是我们还是需要创建一种非常高效并且功能强大的方法来提取关键字和关键字。 这就是KeyBERT诞生的初衷！ 它使用BERT嵌入和简单的余弦相似性来查找文档中与文档本身最相似的子短语。\n首先，使用BERT提取文档向量(嵌入)以获取文档级表示。 然后，针对N元语法词/短语提取词向量。 最后，我们使用余弦相似度来查找与文档最相似的词/短语。 然后，可以将最相似的词识定义为最能描述整个文档的词。\nKeyBERT可能不是唯一的提取关键词的方法，它的定位主要是一种用于创建关键字和关键词的快速简便的方法。 尽管有很多出色的论文和解决方案都使用BERT嵌入，但是很少有直接基于BERT的解决方案，该工具无需从头开始进行训练模型，初学者也可直接使用\n原理介绍 动手实验  直接使用，代码：https://github.com/jackie930/financial-Forecast-RCA/blob/main/code/keyword_extraction/KeyBert/demo.ipynb 部署成推理节点使用， 代码：https://github.com/jackie930/financial-Forecast-RCA/blob/main/code/keyword_extraction/KeyBert/deploy.ipynb  参考  代码：https://github.com/MaartenGr/KeyBERT paper：https://www.preprints.org/manuscript/201908.0073/download/final_file  "},{"uri":"/01introduction.html","title":"基于Amazon SageMaker训练一个关键词抽取模型以及部署","tags":[],"description":"","content":"什么是关键词抽取 在自然语言处理领域，处理海量的文本文件最关键的是要把用户最关心的问题提取出来。而无论是对于长文本还是短文本，往往可以通过一些关键词窥探整个文本的主题思想。与此同时，不管是基于文本的推荐还是基于文本的搜索，对于文本关键词的依赖也很大，关键词提取的准确程度直接关系到推荐系统或者搜索系统的最终效果。因此，关键词提取在文本挖掘领域是一个很重要的部分。\n方法对比  KeyBert  无监督（自监督） 基于语意信息非统计频次 用于无标注场景下的使用，替换传统的textrank   T5-prompt  需要训练 基于prompt-learning 可扩展   UIE  小样本 实体抽取预训练模型强大 专业领域表现优秀    "},{"uri":"/01introduction/uie.html","title":"1.2 UIE","tags":[],"description":"","content":"使用场景 信息抽取（IE）是一个从文本到结构的转换过程。常见的实体、关系、事件分别采取Span、Triplet、Record形式的异构结构。\n曾几何时，当我们面对各种复杂多样的IE任务，我们总会造各式各样IE模型的轮子，来满足不同复杂任务的多变需求。\n真实的情况是：针对不同任务设定，需要针对特定领域schema建模，不同IE模型被单个训练、不共享，一个公司可能需要管理众多IE模型。\n因而，随着NLP的发展，统一/通用的IE是一个众望所归的模型。\nUIE来自2022ACL, 他可以做到：\n 统一地建模不同的IE任务 自适应地生成目标结构 从不同的知识来源统一学习通用的信息抽取能力。  原理介绍 UIE提出的统一生成框架，基于T5模型进行了IE预训练，在实体、关系、事件和情感等4个信息抽取任务、13个数据集的全监督、低资源和少样本设置下均取得了SOTA性能。\n优势  使用简单：用户可以使用自然语言自定义抽取目标，无需训练即可统一抽取输入文本中的对应信息。实现开箱即用，并满足各类信息抽取需求。 降本增效：以往的信息抽取技术需要大量标注数据才能保证信息抽取的效果，为了提高开发过程中的开发效率，减少不必要的重复工作时间，开放域信息抽取可以实现零样本（zero-shot）或者少样本（few-shot）抽取，大幅度降低标注数据依赖，在降低成本的同时，还提升了效果。 效果领先：开放域信息抽取在多种场景，多种任务上，均有不俗的表现。  动手实验 https://github.com/jackie930/financial-Forecast-RCA/blob/main/code/keyword_extraction/UIE/uie_byos_gpu.ipynb\n参考  uie 源码 https://github.com/universal-ie/UIE paddlenlp https://github.com/PaddlePaddle/PaddleNLP/tree/develop/model_zoo/uie paper https://arxiv.org/pdf/2203.12277.pdf  "},{"uri":"/02textrank.html","title":"基于Amazon SageMaker训练一个端到端阅读行为分类+归因模型以及部署","tags":[],"description":"","content":""},{"uri":"/01introduction/t5-prompt.html","title":"1.3 T5-Prompt","tags":[],"description":"","content":"NLP 模型的发展 过去许多机器学习方法是基于全监督学习 (fully supervised learning) 的.\n由于监督学习需要大量的数据学习性能优异的模型, 而在 NLP 中大规模训练数据(指为特定任务而标注好的数据)是不足的, 因此在深度学习出现之前研究者通常聚焦于特征工程 (feature engineering), 即利用领域知识从数据中提取好的特征;\n在深度学习出现之后, 由于特征可以从数据中习得, 因此研究者转向了结构工程 (architecture engineering), 即通过通过设计一个合适的网络结构来把归纳偏置 (inductive bias) 引入模型中, 从而有利于学习好的特征.\n在 2017-2019 年, NLP 模型开始转向一个新的模式 (BERT), 即预训练 + 微调 (pre-train and fine-tune). 在这个模式中, 先用一个固定的结构预训练一个语言模型 (language model, LM), 预训练的方式就是让模型补全上下文 (比如完形填空).\n由于预训练不需要专家知识, 因此可以在网络上搜集的大规模文本上直接进行训练. 然后这个 LM 通过引入额外的参数或微调来适应到下游任务上. 此时研究者转向了 目标工程 (objective engineering), 即为预训练任务和微调任务设计更好的目标函数.\nprompt learning 介绍 在做 objective engineering 的过程中, 研究者发现让下游任务的目标与预训练的目标对齐是有好的. 因此下游任务通过引入文本提示符 (textual prompt), 把原来的任务目标重构为与预训练模型一致的填空题.\n比如一个输入 “I missed the bus today.” 的重构:\n情感预测任务. 输入: “I missed the bus today. I felt so ___.” 其中 “I felt so” 就是提示词 (prompt), 然后使用 LM 用一个表示情感的词填空. 翻译任务. 输入: “English: I missed the bus today. French: ___.” 其中 “English:” 和 “French:” 就是提示词, 然后使用 LM 应该再空位填入相应的法语句子.  我们发现用不同的 prompt 加到相同的输入上, 就能实现不同的任务, 从而使得下游任务可以很好的对齐到预训练任务上, 实现更好的预测效果.\n后来研究者发现, 在同一个任务上使用不同的 prompt, 预测效果也会有显著差异, 因此现在有许多研究开始聚焦于 prompt engineering.\nT5原理介绍 动手实验 https://github.com/jackie930/financial-Forecast-RCA/blob/main/code/keyword_extraction/T5-Prompt/model.ipynb\n"},{"uri":"/","title":"AWS Datalab- 基于阅读行为的用户归因分析","tags":[],"description":"","content":"Author\n JUNYI LIU (AWS GCR Sr. Applied Scientist) KAIGE YANG (AWS GCR Applied Scientist)  概述 本次workshop分为几个部分\n 基于Amazon SageMaker训练一个关键词抽取模型以及部署 基于Amazon SageMaker训练一个端到端阅读行为分类+归因模型以及部署  本次 workshop 前提 本次 workshop 建议在 us-east-1 Region 使用。为了演示方便，所以本 workshop 所有的演示都会以us-east-1 Region 为例。\n"},{"uri":"/categories.html","title":"Categories","tags":[],"description":"","content":""},{"uri":"/tags.html","title":"Tags","tags":[],"description":"","content":""}]