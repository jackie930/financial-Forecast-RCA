<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>基于Amazon SageMaker训练端到端阅读行为分类+归因模型以及部署 on Datalab Workshop</title><link>/02textrank.html</link><description>Recent content in 基于Amazon SageMaker训练端到端阅读行为分类+归因模型以及部署 on Datalab Workshop</description><generator>Hugo -- gohugo.io</generator><language>en-US</language><atom:link href="/02textrank/index.xml" rel="self" type="application/rss+xml"/><item><title>2.1 阅读行为分类模型介绍</title><link>/02textrank/text-classifier.html</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>/02textrank/text-classifier.html</guid><description>阅读行为分类模型介绍 任务概述 用户浏览投资相关内容（新闻，feed， 报告 等） 并产生入金行为 基于用户浏览内容构建文本分类模型判断是否有入金行为 数据形式 已有数据包含用户和浏览内容的相关信息 数据的基本概况
数据包含4479 个用户， 20180 条数据 其中 1806 个用户具有入金行为 占比 40.6% 其中 4968 条数据包含入金行为 占比 24.6% 其中 2399 个用户 只有1条记录，占比 53%， 超过5 条数据的用户占比 13% 数据准备 数据清洗： 除去标点和数字 缺失值填充： 空格代替缺失值 异常值处理： 个别用户浏览超过800+条内容 文本分类模型搭建 基于BERT 与训练模型 创建文本分类模型。 基本架构如下
基于单条文本预测模型（a.k.a. BERT) 基于最近三条浏览文本的预测模型 （a.k.a, BERT+CNN, BERT+LSTM) 动手实验 https://github.com/jackie930/financial-Forecast-RCA/tree/main/code/textcls_rca/code</description></item><item><title>2.2 SHAP RCA</title><link>/02textrank/shap.html</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>/02textrank/shap.html</guid><description>SHAP 归因模型介绍 概述 SHAP 归因模型分析每一个输入变量对与模型输出的影响大小
相关链接 SHAP 官方文档 External Link SHAP 论文 External Link SHAP 相关blog External Link 原理 SHAP 分析并计算 每个输入变量的对模型输出的影响大小 i.e., shaply-value 原理实践 假设 f 为文本分类模型。 该模型输入为文本，输出 [0,1] 举例 文本输入为： text= &amp;lsquo;suprising twits and turns&amp;rsquo;。 本输入中包含 4 个输入变量 F={superising, twists, and , turns} SHAP 模型 计算并输出 每一个变量的shaply-value 以变量 superising 为例， 下面展示shaply-value的具体计算过程 动手实验 https://github.com/jackie930/financial-Forecast-RCA/tree/main/code/textcls_rca/code</description></item></channel></rss>