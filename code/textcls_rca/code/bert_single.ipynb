{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4cf71813",
   "metadata": {},
   "source": [
    "## Install Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "255b3885",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install transformers\n",
    "!pip install shap\n",
    "!pip install torchmetrics\n",
    "!pip install seaborn\n",
    "!pip install matplotlib\n",
    "!pip install pandas\n",
    "!pip install numpy \n",
    "!pip install tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5c48628",
   "metadata": {},
   "source": [
    "## Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80de7a92",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import scipy as sp\n",
    "from torch import nn\n",
    "import torch\n",
    "import numpy as np\n",
    "from transformers import BertTokenizer\n",
    "from tqdm import tqdm\n",
    "from torchmetrics import AUROC\n",
    "%matplotlib inline\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import font_manager\n",
    "import seaborn as sns\n",
    "sns.set_style(\"whitegrid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5ef2abc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from shap_utils import *\n",
    "from data_utils import *\n",
    "from models import TextClassifierModel, Dataset, train_model, evaluate_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a679eb70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add font family into matplotlib and seaborn for showing Chinese Text\n",
    "font_dirs = ['../fonts/']\n",
    "font_files = font_manager.findSystemFonts(fontpaths=font_dirs)\n",
    "for font_file in font_files:\n",
    "    font_manager.fontManager.addfont(font_file)\n",
    "\n",
    "plt.rcParams['font.family'] = 'SimHei'\n",
    "\n",
    "sns.set(font_scale=2)\n",
    "sns.set(font=\"SimHei\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a13758a",
   "metadata": {},
   "source": [
    "## Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d30a2d40",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_path = '../data/'\n",
    "data_name = 'task_output_5313.txt'\n",
    "df = clean_data(input_path, data_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed0a24b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for each user, keep the most recent 50 records. most users have < 5 records\n",
    "sort_df = df.sort_values(['event_time'], ascending=True).groupby('user_no')\n",
    "df = sort_df.head(50).reset_index()\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec2bb5f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = df[:500]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4eff4a53",
   "metadata": {},
   "source": [
    "## Define the input for text-classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76a6ed84",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['input_info'] = df['clean_title'] + ' ' + df['clean_abstract']\n",
    "df['input_info'].head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e90d66d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split dataset into training, validation and testing dataset\n",
    "np.random.seed(112)\n",
    "df_train, df_val, df_test = np.split(df.sample(frac=1, random_state=42),[int(.8*len(df)), int(.9*len(df))])\n",
    "print(len(df_train),len(df_val), len(df_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db91a0bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# find the average text length which used as max-length in Tokenizer\n",
    "length = int(df['input_info'].apply(len).mean())\n",
    "length = np.min([200, length])\n",
    "print('length', length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67ce4d04",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('bert-base-multilingual-cased', do_lower_case = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d47475a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# construct pytorch Dataset \n",
    "train_dataset, val_dataset, test_dataset = Dataset(df_train, length, tokenizer), Dataset(df_val, length, tokenizer), Dataset(df_test, length, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91c7b259",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = TextClassifierModel(bert_freeze=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30282a1f",
   "metadata": {},
   "source": [
    "## Import tokenizer and BERT "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e2981a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyperparameters for training \n",
    "EPOCHS = 10\n",
    "LR = 1e-5\n",
    "BATCH_SIZE = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaa9df5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# classification metric: ROC-AUC\n",
    "auroc = AUROC(num_classes=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e63a9fd0",
   "metadata": {},
   "source": [
    "## Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c56486fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train the text-classifier model\n",
    "train_model(model, train_dataset, val_dataset, auroc, LR, EPOCHS, BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "531d7d08",
   "metadata": {},
   "source": [
    "## Evaluate Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16e7fa65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate the text-classifier model\n",
    "auroc = AUROC(num_classes=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "116500da",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_model(model, test_dataset, auroc, BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe0be598",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # torch.save(model, '../saved_models/bert_model.pt')\n",
    "# # model = torch.load('../saved_models/bert_model.pt')\n",
    "# # device = torch.device('cuda')\n",
    "# # model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbba1533",
   "metadata": {},
   "source": [
    "## Build SHAP explainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "152ad9a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "388383a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the classifier model which will be used in SHAP\n",
    "def classifier_model(x):\n",
    "    tv = [tokenizer(v, padding='max_length', max_length=200, truncation=True) for v in x]\n",
    "    mask = torch.tensor([tv[i]['attention_mask'] for i in range(x.shape[0])]).unsqueeze(1).cuda()\n",
    "    input_id = torch.tensor([tv[i]['input_ids'] for i in range(x.shape[0])]).cuda()\n",
    "    logits = model(input_id, mask).detach().cpu().numpy()\n",
    "    scores = (np.exp(logits).T / np.exp(logits).sum(-1)).T\n",
    "    outputs = scores[:,1]\n",
    "    return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "942ad3aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # test classifier_model to make sure it works as expected\n",
    "# df_try = df[['input_info']][:10]\n",
    "# classifier_model(df_try['input_info'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1d6ba30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# construct SHAP explainer: combine SHAP and classificer model\n",
    "explainer = shap.Explainer(classifier_model, tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acff6550",
   "metadata": {},
   "source": [
    "## Run SHAP explainer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68c3132f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# select test input for SHAP explainer: only select data rows with label==1 (positive data rows)\n",
    "shap_input = df[df.key_label == 1]['input_info'][:10].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cf6ffbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the shaply value of input\n",
    "shap_values = explainer(shap_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc9bdea2",
   "metadata": {},
   "source": [
    "## Show shaply value of tokens in single input text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a8396da",
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.plots.text(shap_values[3], grouping_threshold=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5da06a36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# shap.plots.text(shap_values[3], grouping_threshold=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e426c08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# shap.plots.text(shap_values[3], grouping_threshold=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d5ae558",
   "metadata": {},
   "source": [
    "## Show Bar Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ca15339",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_top_n_tokens(shap_values, top_n=10, grouping_threshold=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73876e46",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_top_n_tokens(shap_values, top_n=10, grouping_threshold=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00659331",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_top_n_tokens(shap_values, top_n=10, grouping_threshold=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3662445",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from scipy.cluster.hierarchy import dendrogram\n",
    "# values, clustering = unpack_shap_explanation_contents(shap_values[0])\n",
    "# fig = plt.figure(figsize=(12, 6))\n",
    "# dn = dendrogram(clustering)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0eaa211",
   "metadata": {},
   "source": [
    "## Find shaply value of Tags (industry and concept)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dba5aae",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install fuzzywuzzy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39737639",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fuzzywuzzy import fuzz\n",
    "from fuzzywuzzy import process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99baa91c",
   "metadata": {},
   "outputs": [],
   "source": [
    "tags = df['tags'].apply(lambda x: [i for i in x.split(' ')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a2aeba9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# collect all tags\n",
    "all_tags = []\n",
    "for tag in tags:\n",
    "    all_tags.extend(tag)\n",
    "\n",
    "unique_tags = np.unique(all_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82ddf530",
   "metadata": {},
   "outputs": [],
   "source": [
    "# collect all tokens and shaply values\n",
    "all_tokens = []\n",
    "all_values = []\n",
    "for i, v in enumerate(shap_values):\n",
    "    values, clustering = unpack_shap_explanation_contents(v)\n",
    "    tokens, values, group_sizes = process_shap_values(v.data, values, 0.1, '', clustering)\n",
    "    all_tokens += list(tokens)\n",
    "    all_values += list(values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d84dde87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# find the most similar token for each tag \n",
    "tag_values = []\n",
    "for tag in unique_tags:\n",
    "    matched_token = process.extract(tag, all_tokens, limit=3)[0][0]\n",
    "    index = np.where(np.array(all_tokens)==matched_token)[0][0]    \n",
    "    value = all_values[index]\n",
    "    tag_values.extend([value])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce27451b",
   "metadata": {},
   "outputs": [],
   "source": [
    "value_index = np.argsort(tag_values)\n",
    "sorted_values = np.array(tag_values)[value_index]\n",
    "sorted_tags = list(np.array(unique_tags)[value_index])\n",
    "data_dict = {'tags': sorted_tags[::-1], 'shaply-value': sorted_values[::-1]}\n",
    "score_df = pd.DataFrame(data_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bebc7a9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.barplot(data=score_df[:20], x=\"shaply-value\", y=\"tags\", color='c')\n",
    "plt.ylabel('') \n",
    "plt.title('top %s tags'%(20), fontsize=12)\n",
    "plt.tight_layout()\n",
    "# plt.savefig('../data/'+'tags_values'+'.png', dpi=100)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd1acc4b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a45ce7c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_p38",
   "language": "python",
   "name": "conda_pytorch_p38"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
