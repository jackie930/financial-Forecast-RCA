{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PaddlePaddle BYOS\n",
    "\n",
    "## Pre-requisites\n",
    "\n",
    "This notebook shows how to use the SageMaker Python SDK to run your code in a local container before deploying to SageMaker's managed training or hosting environments.  This can speed up iterative testing and debugging while using the same familiar Python SDK interface.  Just change your estimator's `train_instance_type` to `local` (or `local_gpu` if you're using an ml.p2 or ml.p3 notebook instance).\n",
    "\n",
    "In order to use this feature you'll need to install docker-compose (and nvidia-docker if training with a GPU).\n",
    "\n",
    "**Note, you can only run a single local notebook at one time.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !/bin/bash ./utils/setup.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview\n",
    "\n",
    "The **SageMaker Python SDK** helps you deploy your models for training and hosting in optimized, productions ready containers in SageMaker. The SageMaker Python SDK is easy to use, modular, extensible and compatible with TensorFlow, MXNet, PyTorch and Chainer. This tutorial focuses on how to create a convolutional neural network model to train the [Cifar10 dataset](https://www.cs.toronto.edu/~kriz/cifar.html) using **PyTorch in local mode**.\n",
    "\n",
    "### Set up the environment\n",
    "\n",
    "This notebook was created and tested on a single ml.p2.xlarge notebook instance.\n",
    "\n",
    "Let's start by specifying:\n",
    "\n",
    "- The S3 bucket and prefix that you want to use for training and model data. This should be within the same region as the Notebook Instance, training, and hosting.\n",
    "- The IAM role arn used to give training and hosting access to your data. See the documentation for how to create these. Note, if more than one role is required for notebook instances, training, and/or hosting, please replace the sagemaker.get_execution_role() with appropriate full IAM role arn string(s)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sagemaker\n",
    "\n",
    "sagemaker_session = sagemaker.Session()\n",
    "\n",
    "bucket = sagemaker_session.default_bucket()\n",
    "prefix = 'sagemaker/DEMO-PaddleNLP'\n",
    "\n",
    "role = sagemaker.get_execution_role()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import subprocess\n",
    "\n",
    "# instance_type = 'local'\n",
    "\n",
    "# if subprocess.call('nvidia-smi') == 0:\n",
    "#     ## Set type to GPU if one is present\n",
    "#     instance_type = 'local_gpu'\n",
    "    \n",
    "# print(\"Instance type = \" + instance_type)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "with open('../train/all.txt') as f:\n",
    "    data = f.readlines()\n",
    "\n",
    "split = 0.7\n",
    "split_index = int(len(data) * split)\n",
    "training = data[:split_index]\n",
    "testing = data[split_index:]\n",
    "\n",
    "# open file in write mode\n",
    "with open(r'../train/train.txt', 'w') as fp:\n",
    "    for item in training:\n",
    "        # write each item on a new line\n",
    "        fp.write(\"%s\\n\" % item)\n",
    "    print('Done')\n",
    "\n",
    "with open(r'../train/dev.txt', 'w') as fp:\n",
    "    for item in testing:\n",
    "        # write each item on a new line\n",
    "        fp.write(item)\n",
    "    print('Done')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Upload the data\n",
    "We use the ```sagemaker.Session.upload_data``` function to upload our datasets to an S3 location. The return value inputs identifies the location -- we will use this later when we start the training job."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_location = sagemaker.Session().upload_data(path = \"../train\", key_prefix=prefix)\n",
    "# base_dir = 'file:///home/ec2-user/SageMaker/paddlenlp_sagemaker/data/'\n",
    "# inputs = {'training': base_dir}\n",
    "# print(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'s3://sagemaker-us-east-1-726335585155/sagemaker/DEMO-PaddleNLP'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_location"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Script Functions\n",
    "\n",
    "SageMaker invokes the main function defined within your training script for training. When deploying your trained model to an endpoint, the model_fn() is called to determine how to load your trained model. The model_fn() along with a few other functions list below are called to enable predictions on SageMaker.\n",
    "\n",
    "### [Predicting Functions](https://github.com/aws/sagemaker-pytorch-containers/blob/master/src/sagemaker_pytorch_container/serving.py)\n",
    "* model_fn(model_dir) - loads your model.\n",
    "* input_fn(serialized_input_data, content_type) - deserializes predictions to predict_fn.\n",
    "* output_fn(prediction_output, accept) - serializes predictions from predict_fn.\n",
    "* predict_fn(input_data, model) - calls a model on data deserialized in input_fn.\n",
    "\n",
    "The model_fn() is the only function that doesn't have a default implementation and is required by the user for using PyTorch on SageMaker. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a training job using the sagemaker.PyTorch estimator\n",
    "\n",
    "The `PyTorch` class allows us to run our training function on SageMaker. We need to configure it with our training script, an IAM role, the number of training instances, and the training instance type. For local training with GPU, we could set this to \"local_gpu\".  In this case, `instance_type` was set above based on your whether you're running a GPU instance.\n",
    "\n",
    "After we've constructed our `PyTorch` object, we fit it using the data we uploaded to S3. Even though we're in local mode, using S3 as our data source makes sense because it maintains consistency with how SageMaker's distributed, managed training ingests data.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SageMaker Training using GPU instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'training': 's3://sagemaker-us-east-1-726335585155/sagemaker/DEMO-PaddleNLP'}\n"
     ]
    }
   ],
   "source": [
    "inputs = {'training': data_location}\n",
    "\n",
    "print(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#upload uie-base-en pretrain\n",
    "\n",
    "uie_en_model_s3 = sagemaker.Session().upload_data(path = \"../uie-base-en/taskflow/information_extraction/uie-base-en\", key_prefix=\"model_uie_base_en\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-09-09 03:45:25 Starting - Starting the training job...ProfilerReport-1662695125: InProgress\n",
      "...\n",
      "2022-09-09 03:46:09 Starting - Preparing the instances for training.........\n",
      "2022-09-09 03:47:50 Downloading - Downloading input data...\n",
      "2022-09-09 03:48:10 Training - Downloading the training image..........................\u001b[34mbash: cannot set terminal process group (-1): Inappropriate ioctl for device\u001b[0m\n",
      "\u001b[34mbash: no job control in this shell\u001b[0m\n",
      "\u001b[34m2022-09-09 03:52:35,846 sagemaker-training-toolkit INFO     Imported framework sagemaker_pytorch_container.training\u001b[0m\n",
      "\u001b[34m2022-09-09 03:52:35,883 sagemaker_pytorch_container.training INFO     Block until all host DNS lookups succeed.\u001b[0m\n",
      "\u001b[34m2022-09-09 03:52:35,891 sagemaker_pytorch_container.training INFO     Invoking user training script.\u001b[0m\n",
      "\u001b[34m2022-09-09 03:52:36,461 sagemaker-training-toolkit INFO     Installing dependencies from requirements.txt:\u001b[0m\n",
      "\u001b[34m/opt/conda/bin/python -m pip install -r requirements.txt\u001b[0m\n",
      "\u001b[34mLooking in indexes: https://opentuna.cn/pypi/web/simple/\u001b[0m\n",
      "\u001b[34mCollecting paddlepaddle-gpu\u001b[0m\n",
      "\u001b[34mDownloading https://opentuna.cn/pypi/web/packages/fb/f2/6b6ae62d5ecd916d61e1f527cb14990038d473cc670c30045f80b557e6e1/paddlepaddle_gpu-2.3.1-cp38-cp38-manylinux1_x86_64.whl (393.9 MB)\u001b[0m\n",
      "\n",
      "2022-09-09 03:52:51 Training - Training image download completed. Training in progress.\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 393.9/393.9 MB 2.2 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mCollecting paddlenlp\u001b[0m\n",
      "\u001b[34mDownloading https://opentuna.cn/pypi/web/packages/8e/e1/94cdbaca400a57687a8529213776468f003b64b6e35a6f4acf6b6539f543/paddlenlp-2.3.4-py3-none-any.whl (1.4 MB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.4/1.4 MB 1.1 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: six in /opt/conda/lib/python3.8/site-packages (from paddlepaddle-gpu->-r requirements.txt (line 2)) (1.16.0)\u001b[0m\n",
      "\u001b[34mCollecting astor\u001b[0m\n",
      "\u001b[34mDownloading https://opentuna.cn/pypi/web/packages/c3/88/97eef84f48fa04fbd6750e62dcceafba6c63c81b7ac1420856c8dcc0a3f9/astor-0.8.1-py2.py3-none-any.whl (27 kB)\u001b[0m\n",
      "\u001b[34mCollecting opt-einsum==3.3.0\u001b[0m\n",
      "\u001b[34mDownloading https://opentuna.cn/pypi/web/packages/bc/19/404708a7e54ad2798907210462fd950c3442ea51acc8790f3da48d2bee8b/opt_einsum-3.3.0-py3-none-any.whl (65 kB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 65.5/65.5 kB 3.4 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mCollecting protobuf<=3.20.0,>=3.1.0\u001b[0m\n",
      "\u001b[34mDownloading https://opentuna.cn/pypi/web/packages/88/88/cd55f87e896b82a3aba8e6c0affc077de51f7321cf730622b17ef7b0f69c/protobuf-3.20.0-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.whl (1.0 MB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.0/1.0 MB 3.8 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mCollecting paddle-bfloat==0.1.7\u001b[0m\n",
      "\u001b[34mDownloading https://opentuna.cn/pypi/web/packages/76/d7/ba0e1aeec33e20c78af5cf2fdbb7e7cabfe4679557e68759a17c97e03540/paddle_bfloat-0.1.7-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (385 kB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 385.5/385.5 kB 6.5 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: decorator in /opt/conda/lib/python3.8/site-packages (from paddlepaddle-gpu->-r requirements.txt (line 2)) (5.1.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: numpy>=1.13 in /opt/conda/lib/python3.8/site-packages (from paddlepaddle-gpu->-r requirements.txt (line 2)) (1.22.3)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: Pillow in /opt/conda/lib/python3.8/site-packages (from paddlepaddle-gpu->-r requirements.txt (line 2)) (9.1.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: requests>=2.20.0 in /opt/conda/lib/python3.8/site-packages (from paddlepaddle-gpu->-r requirements.txt (line 2)) (2.27.1)\u001b[0m\n",
      "\u001b[34mCollecting sentencepiece\u001b[0m\n",
      "\u001b[34mDownloading https://opentuna.cn/pypi/web/packages/68/91/ded0f64f90abfc5413c620fc345a0aef1e7ff5addda8704cc6b3bf589c64/sentencepiece-0.1.96-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.2/1.2 MB 7.2 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mCollecting jieba\u001b[0m\n",
      "\u001b[34mDownloading https://opentuna.cn/pypi/web/packages/c6/cb/18eeb235f833b726522d7ebed54f2278ce28ba9438e3135ab0278d9792a2/jieba-0.42.1.tar.gz (19.2 MB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 19.2/19.2 MB 12.2 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mPreparing metadata (setup.py): started\u001b[0m\n",
      "\u001b[34mPreparing metadata (setup.py): finished with status 'done'\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: tqdm in /opt/conda/lib/python3.8/site-packages (from paddlenlp->-r requirements.txt (line 3)) (4.61.2)\u001b[0m\n",
      "\u001b[34mCollecting dill<0.3.5\u001b[0m\n",
      "\u001b[34mDownloading https://opentuna.cn/pypi/web/packages/b6/c3/973676ceb86b60835bb3978c6db67a5dc06be6cfdbd14ef0f5a13e3fc9fd/dill-0.3.4-py2.py3-none-any.whl (86 kB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 86.9/86.9 kB 3.0 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mCollecting paddlefsl\u001b[0m\n",
      "\u001b[34mDownloading https://opentuna.cn/pypi/web/packages/fb/4a/25d1959a8f1fe5ee400f32fc9fc8b56d4fd6fc25315e23c0171f6e705e2a/paddlefsl-1.1.0-py3-none-any.whl (101 kB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 101.0/101.0 kB 2.7 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mCollecting multiprocess<=0.70.12.2\u001b[0m\n",
      "\u001b[34mDownloading https://opentuna.cn/pypi/web/packages/e6/22/b09b8394f8c86ff0cfebd725ea96bba0accd4a4b2be437bcba6a0cf7d1c3/multiprocess-0.70.12.2-py38-none-any.whl (128 kB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 128.3/128.3 kB 3.2 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mCollecting datasets>=2.0.0\u001b[0m\n",
      "\u001b[34mDownloading https://opentuna.cn/pypi/web/packages/98/29/f381f8a633fed2c4f41c191498c3bc43d91a8e44c5202a8b0b2bd8b1acf3/datasets-2.3.2-py3-none-any.whl (362 kB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 362.3/362.3 kB 3.2 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mCollecting colorlog\u001b[0m\n",
      "\u001b[34mDownloading https://opentuna.cn/pypi/web/packages/7d/54/e24efe5469ecb2710112055de87a2900e9494810bcfc25c12c7a0723eb64/colorlog-6.6.0-py2.py3-none-any.whl (11 kB)\u001b[0m\n",
      "\u001b[34mCollecting seqeval\u001b[0m\n",
      "\u001b[34mDownloading https://opentuna.cn/pypi/web/packages/9d/2d/233c79d5b4e5ab1dbf111242299153f3caddddbb691219f363ad55ce783d/seqeval-1.2.2.tar.gz (43 kB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 43.6/43.6 kB 5.4 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mPreparing metadata (setup.py): started\u001b[0m\n",
      "\u001b[34mPreparing metadata (setup.py): finished with status 'done'\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: colorama in /opt/conda/lib/python3.8/site-packages (from paddlenlp->-r requirements.txt (line 3)) (0.4.4)\u001b[0m\n",
      "\u001b[34mCollecting paddle2onnx\u001b[0m\n",
      "\u001b[34mDownloading https://opentuna.cn/pypi/web/packages/78/76/811c8c897d68e211bc7ba13fa6161f54747eb717bffae80db0ea09ca2e43/paddle2onnx-0.9.8-cp38-cp38-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (2.9 MB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 2.9/2.9 MB 1.9 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: fsspec[http]>=2021.05.0 in /opt/conda/lib/python3.8/site-packages (from datasets>=2.0.0->paddlenlp->-r requirements.txt (line 3)) (2022.5.0)\u001b[0m\n",
      "\u001b[34mCollecting xxhash\u001b[0m\n",
      "\u001b[34mDownloading https://opentuna.cn/pypi/web/packages/6a/cf/50f4cfde85d90c2b3e9c98b46e17d190bbdd97b54d3e0876e1d9360e487f/xxhash-3.0.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (212 kB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 212.1/212.1 kB 5.8 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mCollecting huggingface-hub<1.0.0,>=0.1.0\u001b[0m\n",
      "\u001b[34mDownloading https://opentuna.cn/pypi/web/packages/d8/2c/9af8451ab780598e3b26a84d4f0e3844841456657401eb6843fdb622bb41/huggingface_hub-0.8.1-py3-none-any.whl (101 kB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 101.5/101.5 kB 4.7 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mCollecting responses<0.19\u001b[0m\n",
      "\u001b[34mDownloading https://opentuna.cn/pypi/web/packages/79/f3/2b3a6dc5986303b3dd1bbbcf482022acb2583c428cd23f0b6d37b1a1a519/responses-0.18.0-py3-none-any.whl (38 kB)\u001b[0m\n",
      "\u001b[34mCollecting tqdm\u001b[0m\n",
      "\u001b[34mDownloading https://opentuna.cn/pypi/web/packages/8a/c4/d15f1e627fff25443ded77ea70a7b5532d6371498f9285d44d62587e209c/tqdm-4.64.0-py2.py3-none-any.whl (78 kB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 78.4/78.4 kB 4.2 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mCollecting aiohttp\u001b[0m\n",
      "\u001b[34mDownloading https://opentuna.cn/pypi/web/packages/38/71/e1db3f96fa85f77906ef002a08fa8d02dbdb3292180d41eb1b17ddab72bf/aiohttp-3.8.1-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.3 MB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.3/1.3 MB 2.4 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: packaging in /opt/conda/lib/python3.8/site-packages (from datasets>=2.0.0->paddlenlp->-r requirements.txt (line 3)) (21.2)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pyarrow>=6.0.0 in /opt/conda/lib/python3.8/site-packages (from datasets>=2.0.0->paddlenlp->-r requirements.txt (line 3)) (6.0.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pandas in /opt/conda/lib/python3.8/site-packages (from datasets>=2.0.0->paddlenlp->-r requirements.txt (line 3)) (1.2.4)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.8/site-packages (from requests>=2.20.0->paddlepaddle-gpu->-r requirements.txt (line 2)) (1.26.6)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.8/site-packages (from requests>=2.20.0->paddlepaddle-gpu->-r requirements.txt (line 2)) (2022.5.18.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: charset-normalizer~=2.0.0 in /opt/conda/lib/python3.8/site-packages (from requests>=2.20.0->paddlepaddle-gpu->-r requirements.txt (line 2)) (2.0.4)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.8/site-packages (from requests>=2.20.0->paddlepaddle-gpu->-r requirements.txt (line 2)) (2.10)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: scikit-learn>=0.21.3 in /opt/conda/lib/python3.8/site-packages (from seqeval->paddlenlp->-r requirements.txt (line 3)) (1.0.2)\u001b[0m\n",
      "\u001b[34mCollecting filelock\u001b[0m\n",
      "\u001b[34mDownloading https://opentuna.cn/pypi/web/packages/a6/d5/17f02b379525d1ff9678bfa58eb9548f561c8826deb0b85797aa0eed582d/filelock-3.7.1-py3-none-any.whl (10 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.8/site-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets>=2.0.0->paddlenlp->-r requirements.txt (line 3)) (3.10.0.2)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.8/site-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets>=2.0.0->paddlenlp->-r requirements.txt (line 3)) (5.4.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pyparsing<3,>=2.0.2 in /opt/conda/lib/python3.8/site-packages (from packaging->datasets>=2.0.0->paddlenlp->-r requirements.txt (line 3)) (2.4.7)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: joblib>=0.11 in /opt/conda/lib/python3.8/site-packages (from scikit-learn>=0.21.3->seqeval->paddlenlp->-r requirements.txt (line 3)) (1.1.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: scipy>=1.1.0 in /opt/conda/lib/python3.8/site-packages (from scikit-learn>=0.21.3->seqeval->paddlenlp->-r requirements.txt (line 3)) (1.8.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.8/site-packages (from scikit-learn>=0.21.3->seqeval->paddlenlp->-r requirements.txt (line 3)) (2.2.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.8/site-packages (from aiohttp->datasets>=2.0.0->paddlenlp->-r requirements.txt (line 3)) (21.4.0)\u001b[0m\n",
      "\u001b[34mCollecting yarl<2.0,>=1.0\u001b[0m\n",
      "\u001b[34mDownloading https://opentuna.cn/pypi/web/packages/aa/a6/a4ddcb1c3d93fc5d77a19b1ec338a3efec65b44345168d8ac9bf8461224a/yarl-1.7.2-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (308 kB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 308.6/308.6 kB 5.7 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mCollecting multidict<7.0,>=4.5\u001b[0m\n",
      "\u001b[34mDownloading https://opentuna.cn/pypi/web/packages/8f/39/a7e04961b4c00d68aba337e3fdef9fd4f666dcd98f41725067a1de5d3399/multidict-6.0.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (121 kB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 121.3/121.3 kB 4.6 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mCollecting aiosignal>=1.1.2\u001b[0m\n",
      "\u001b[34mDownloading https://opentuna.cn/pypi/web/packages/3b/87/fe94898f2d44a93a35d5aa74671ed28094d80753a1113d68b799fab6dc22/aiosignal-1.2.0-py3-none-any.whl (8.2 kB)\u001b[0m\n",
      "\u001b[34mCollecting async-timeout<5.0,>=4.0.0a3\u001b[0m\n",
      "\u001b[34mDownloading https://opentuna.cn/pypi/web/packages/d6/c1/8991e7c5385b897b8c020cdaad718c5b087a6626d1d11a23e1ea87e325a7/async_timeout-4.0.2-py3-none-any.whl (5.8 kB)\u001b[0m\n",
      "\u001b[34mCollecting frozenlist>=1.1.1\u001b[0m\n",
      "\u001b[34mDownloading https://opentuna.cn/pypi/web/packages/3b/76/3d7c273b91e6dc914859f8752d42b763f39ae83782ec9a063a526c816977/frozenlist-1.3.0-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (158 kB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 158.7/158.7 kB 2.5 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: python-dateutil>=2.7.3 in /opt/conda/lib/python3.8/site-packages (from pandas->datasets>=2.0.0->paddlenlp->-r requirements.txt (line 3)) (2.8.2)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pytz>=2017.3 in /opt/conda/lib/python3.8/site-packages (from pandas->datasets>=2.0.0->paddlenlp->-r requirements.txt (line 3)) (2021.3)\u001b[0m\n",
      "\u001b[34mBuilding wheels for collected packages: jieba, seqeval\u001b[0m\n",
      "\u001b[34mBuilding wheel for jieba (setup.py): started\u001b[0m\n",
      "\u001b[34mBuilding wheel for jieba (setup.py): finished with status 'done'\u001b[0m\n",
      "\u001b[34mCreated wheel for jieba: filename=jieba-0.42.1-py3-none-any.whl size=19314477 sha256=389f7ec32e408e3a1a2bd95b4c354e89f778b5be86af2b7bfe34ade7781be733\u001b[0m\n",
      "\u001b[34mStored in directory: /root/.cache/pip/wheels/e9/6d/0d/92e938a9f51144388ebba6a81ebe4206fdd93f9c9de1434ec2\u001b[0m\n",
      "\u001b[34mBuilding wheel for seqeval (setup.py): started\u001b[0m\n",
      "\u001b[34mBuilding wheel for seqeval (setup.py): finished with status 'done'\u001b[0m\n",
      "\u001b[34mCreated wheel for seqeval: filename=seqeval-1.2.2-py3-none-any.whl size=16170 sha256=d302594946cf3b597eb73fb0325ac4ae75e1bda4631871464fec84f7802680c3\u001b[0m\n",
      "\u001b[34mStored in directory: /root/.cache/pip/wheels/6d/ff/58/c7ebcaa099f483531e06ca79ad5802e594d1c97c96c9c0f200\u001b[0m\n",
      "\u001b[34mSuccessfully built jieba seqeval\u001b[0m\n",
      "\u001b[34mInstalling collected packages: sentencepiece, paddle2onnx, paddle-bfloat, jieba, xxhash, tqdm, protobuf, opt-einsum, multidict, frozenlist, filelock, dill, colorlog, async-timeout, astor, yarl, responses, paddlepaddle-gpu, paddlefsl, multiprocess, huggingface-hub, aiosignal, seqeval, aiohttp, datasets, paddlenlp\u001b[0m\n",
      "\u001b[34mAttempting uninstall: tqdm\u001b[0m\n",
      "\u001b[34mFound existing installation: tqdm 4.61.2\u001b[0m\n",
      "\u001b[34mUninstalling tqdm-4.61.2:\u001b[0m\n",
      "\u001b[34mSuccessfully uninstalled tqdm-4.61.2\u001b[0m\n",
      "\u001b[34mAttempting uninstall: protobuf\u001b[0m\n",
      "\u001b[34mFound existing installation: protobuf 3.20.1\u001b[0m\n",
      "\u001b[34mUninstalling protobuf-3.20.1:\u001b[0m\n",
      "\u001b[34mSuccessfully uninstalled protobuf-3.20.1\u001b[0m\n",
      "\u001b[34mAttempting uninstall: dill\u001b[0m\n",
      "\u001b[34mFound existing installation: dill 0.3.5.1\u001b[0m\n",
      "\u001b[34mUninstalling dill-0.3.5.1:\u001b[0m\n",
      "\u001b[34mSuccessfully uninstalled dill-0.3.5.1\u001b[0m\n",
      "\u001b[34mAttempting uninstall: multiprocess\u001b[0m\n",
      "\u001b[34mFound existing installation: multiprocess 0.70.13\u001b[0m\n",
      "\u001b[34mUninstalling multiprocess-0.70.13:\u001b[0m\n",
      "\u001b[34mSuccessfully uninstalled multiprocess-0.70.13\u001b[0m\n",
      "\u001b[34mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\u001b[0m\n",
      "\u001b[34mpathos 0.2.9 requires dill>=0.3.5.1, but you have dill 0.3.4 which is incompatible.\u001b[0m\n",
      "\u001b[34mpathos 0.2.9 requires multiprocess>=0.70.13, but you have multiprocess 0.70.12.2 which is incompatible.\u001b[0m\n",
      "\u001b[34mSuccessfully installed aiohttp-3.8.1 aiosignal-1.2.0 astor-0.8.1 async-timeout-4.0.2 colorlog-6.6.0 datasets-2.3.2 dill-0.3.4 filelock-3.7.1 frozenlist-1.3.0 huggingface-hub-0.8.1 jieba-0.42.1 multidict-6.0.2 multiprocess-0.70.12.2 opt-einsum-3.3.0 paddle-bfloat-0.1.7 paddle2onnx-0.9.8 paddlefsl-1.1.0 paddlenlp-2.3.4 paddlepaddle-gpu-2.3.1 protobuf-3.20.0 responses-0.18.0 sentencepiece-0.1.96 seqeval-1.2.2 tqdm-4.64.0 xxhash-3.0.0 yarl-1.7.2\u001b[0m\n",
      "\u001b[34mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "\u001b[34m[notice] A new release of pip available: 22.1.2 -> 22.2.2\u001b[0m\n",
      "\u001b[34m[notice] To update, run: pip install --upgrade pip\u001b[0m\n",
      "\u001b[34m2022-09-09 03:54:13,334 sagemaker-training-toolkit INFO     Waiting for the process to finish and give a return code.\u001b[0m\n",
      "\u001b[34m2022-09-09 03:54:13,334 sagemaker-training-toolkit INFO     Done waiting for a return code. Received 0 from exiting process.\u001b[0m\n",
      "\u001b[34m2022-09-09 03:54:13,440 sagemaker-training-toolkit INFO     Invoking user script\u001b[0m\n",
      "\u001b[34mTraining Env:\u001b[0m\n",
      "\u001b[34m{\n",
      "    \"additional_framework_parameters\": {},\n",
      "    \"channel_input_dirs\": {\n",
      "        \"training\": \"/opt/ml/input/data/training\"\n",
      "    },\n",
      "    \"current_host\": \"algo-1\",\n",
      "    \"framework_module\": \"sagemaker_pytorch_container.training:main\",\n",
      "    \"hosts\": [\n",
      "        \"algo-1\"\n",
      "    ],\n",
      "    \"hyperparameters\": {\n",
      "        \"batch_size\": 16,\n",
      "        \"dev_path\": \"/opt/ml/input/data/training/dev.txt\",\n",
      "        \"device\": \"gpu\",\n",
      "        \"learning_rate\": 1e-05,\n",
      "        \"logging_steps\": 10,\n",
      "        \"max_seq_len\": 512,\n",
      "        \"model\": \"uie-base\",\n",
      "        \"num_epochs\": 1,\n",
      "        \"save_dir\": \"/opt/ml/model\",\n",
      "        \"seed\": 1000,\n",
      "        \"train_path\": \"/opt/ml/input/data/training/train.txt\",\n",
      "        \"valid_steps\": 100\n",
      "    },\n",
      "    \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "    \"input_data_config\": {\n",
      "        \"training\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        }\n",
      "    },\n",
      "    \"input_dir\": \"/opt/ml/input\",\n",
      "    \"is_master\": true,\n",
      "    \"job_name\": \"pytorch-training-2022-09-09-03-45-25-415\",\n",
      "    \"log_level\": 20,\n",
      "    \"master_hostname\": \"algo-1\",\n",
      "    \"model_dir\": \"/opt/ml/model\",\n",
      "    \"module_dir\": \"s3://sagemaker-us-east-1-726335585155/pytorch-training-2022-09-09-03-45-25-415/source/sourcedir.tar.gz\",\n",
      "    \"module_name\": \"finetune\",\n",
      "    \"network_interface_name\": \"eth0\",\n",
      "    \"num_cpus\": 8,\n",
      "    \"num_gpus\": 1,\n",
      "    \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "    \"output_dir\": \"/opt/ml/output\",\n",
      "    \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "    \"resource_config\": {\n",
      "        \"current_host\": \"algo-1\",\n",
      "        \"current_instance_type\": \"ml.p3.2xlarge\",\n",
      "        \"current_group_name\": \"homogeneousCluster\",\n",
      "        \"hosts\": [\n",
      "            \"algo-1\"\n",
      "        ],\n",
      "        \"instance_groups\": [\n",
      "            {\n",
      "                \"instance_group_name\": \"homogeneousCluster\",\n",
      "                \"instance_type\": \"ml.p3.2xlarge\",\n",
      "                \"hosts\": [\n",
      "                    \"algo-1\"\n",
      "                ]\n",
      "            }\n",
      "        ],\n",
      "        \"network_interface_name\": \"eth0\"\n",
      "    },\n",
      "    \"user_entry_point\": \"finetune.py\"\u001b[0m\n",
      "\u001b[34m}\u001b[0m\n",
      "\u001b[34mEnvironment variables:\u001b[0m\n",
      "\u001b[34mSM_HOSTS=[\"algo-1\"]\u001b[0m\n",
      "\u001b[34mSM_NETWORK_INTERFACE_NAME=eth0\u001b[0m\n",
      "\u001b[34mSM_HPS={\"batch_size\":16,\"dev_path\":\"/opt/ml/input/data/training/dev.txt\",\"device\":\"gpu\",\"learning_rate\":1e-05,\"logging_steps\":10,\"max_seq_len\":512,\"model\":\"uie-base\",\"num_epochs\":1,\"save_dir\":\"/opt/ml/model\",\"seed\":1000,\"train_path\":\"/opt/ml/input/data/training/train.txt\",\"valid_steps\":100}\u001b[0m\n",
      "\u001b[34mSM_USER_ENTRY_POINT=finetune.py\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_PARAMS={}\u001b[0m\n",
      "\u001b[34mSM_RESOURCE_CONFIG={\"current_group_name\":\"homogeneousCluster\",\"current_host\":\"algo-1\",\"current_instance_type\":\"ml.p3.2xlarge\",\"hosts\":[\"algo-1\"],\"instance_groups\":[{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.p3.2xlarge\"}],\"network_interface_name\":\"eth0\"}\u001b[0m\n",
      "\u001b[34mSM_INPUT_DATA_CONFIG={\"training\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}}\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DATA_DIR=/opt/ml/output/data\u001b[0m\n",
      "\u001b[34mSM_CHANNELS=[\"training\"]\u001b[0m\n",
      "\u001b[34mSM_CURRENT_HOST=algo-1\u001b[0m\n",
      "\u001b[34mSM_MODULE_NAME=finetune\u001b[0m\n",
      "\u001b[34mSM_LOG_LEVEL=20\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_MODULE=sagemaker_pytorch_container.training:main\u001b[0m\n",
      "\u001b[34mSM_INPUT_DIR=/opt/ml/input\u001b[0m\n",
      "\u001b[34mSM_INPUT_CONFIG_DIR=/opt/ml/input/config\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DIR=/opt/ml/output\u001b[0m\n",
      "\u001b[34mSM_NUM_CPUS=8\u001b[0m\n",
      "\u001b[34mSM_NUM_GPUS=1\u001b[0m\n",
      "\u001b[34mSM_MODEL_DIR=/opt/ml/model\u001b[0m\n",
      "\u001b[34mSM_MODULE_DIR=s3://sagemaker-us-east-1-726335585155/pytorch-training-2022-09-09-03-45-25-415/source/sourcedir.tar.gz\u001b[0m\n",
      "\u001b[34mSM_TRAINING_ENV={\"additional_framework_parameters\":{},\"channel_input_dirs\":{\"training\":\"/opt/ml/input/data/training\"},\"current_host\":\"algo-1\",\"framework_module\":\"sagemaker_pytorch_container.training:main\",\"hosts\":[\"algo-1\"],\"hyperparameters\":{\"batch_size\":16,\"dev_path\":\"/opt/ml/input/data/training/dev.txt\",\"device\":\"gpu\",\"learning_rate\":1e-05,\"logging_steps\":10,\"max_seq_len\":512,\"model\":\"uie-base\",\"num_epochs\":1,\"save_dir\":\"/opt/ml/model\",\"seed\":1000,\"train_path\":\"/opt/ml/input/data/training/train.txt\",\"valid_steps\":100},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"training\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"is_master\":true,\"job_name\":\"pytorch-training-2022-09-09-03-45-25-415\",\"log_level\":20,\"master_hostname\":\"algo-1\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://sagemaker-us-east-1-726335585155/pytorch-training-2022-09-09-03-45-25-415/source/sourcedir.tar.gz\",\"module_name\":\"finetune\",\"network_interface_name\":\"eth0\",\"num_cpus\":8,\"num_gpus\":1,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_group_name\":\"homogeneousCluster\",\"current_host\":\"algo-1\",\"current_instance_type\":\"ml.p3.2xlarge\",\"hosts\":[\"algo-1\"],\"instance_groups\":[{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.p3.2xlarge\"}],\"network_interface_name\":\"eth0\"},\"user_entry_point\":\"finetune.py\"}\u001b[0m\n",
      "\u001b[34mSM_USER_ARGS=[\"--batch_size\",\"16\",\"--dev_path\",\"/opt/ml/input/data/training/dev.txt\",\"--device\",\"gpu\",\"--learning_rate\",\"1e-05\",\"--logging_steps\",\"10\",\"--max_seq_len\",\"512\",\"--model\",\"uie-base\",\"--num_epochs\",\"1\",\"--save_dir\",\"/opt/ml/model\",\"--seed\",\"1000\",\"--train_path\",\"/opt/ml/input/data/training/train.txt\",\"--valid_steps\",\"100\"]\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_TRAINING=/opt/ml/input/data/training\u001b[0m\n",
      "\u001b[34mSM_HP_BATCH_SIZE=16\u001b[0m\n",
      "\u001b[34mSM_HP_DEV_PATH=/opt/ml/input/data/training/dev.txt\u001b[0m\n",
      "\u001b[34mSM_HP_DEVICE=gpu\u001b[0m\n",
      "\u001b[34mSM_HP_LEARNING_RATE=1e-05\u001b[0m\n",
      "\u001b[34mSM_HP_LOGGING_STEPS=10\u001b[0m\n",
      "\u001b[34mSM_HP_MAX_SEQ_LEN=512\u001b[0m\n",
      "\u001b[34mSM_HP_MODEL=uie-base\u001b[0m\n",
      "\u001b[34mSM_HP_NUM_EPOCHS=1\u001b[0m\n",
      "\u001b[34mSM_HP_SAVE_DIR=/opt/ml/model\u001b[0m\n",
      "\u001b[34mSM_HP_SEED=1000\u001b[0m\n",
      "\u001b[34mSM_HP_TRAIN_PATH=/opt/ml/input/data/training/train.txt\u001b[0m\n",
      "\u001b[34mSM_HP_VALID_STEPS=100\u001b[0m\n",
      "\u001b[34mPYTHONPATH=/opt/ml/code:/opt/conda/bin:/opt/conda/lib/python38.zip:/opt/conda/lib/python3.8:/opt/conda/lib/python3.8/lib-dynload:/opt/conda/lib/python3.8/site-packages\u001b[0m\n",
      "\u001b[34mInvoking script with the following command:\u001b[0m\n",
      "\u001b[34m/opt/conda/bin/python finetune.py --batch_size 16 --dev_path /opt/ml/input/data/training/dev.txt --device gpu --learning_rate 1e-05 --logging_steps 10 --max_seq_len 512 --model uie-base --num_epochs 1 --save_dir /opt/ml/model --seed 1000 --train_path /opt/ml/input/data/training/train.txt --valid_steps 100\u001b[0m\n",
      "\u001b[34m#033[32m[2022-09-09 03:54:17,949] [    INFO]#033[0m - Downloading resource files...#033[0m\u001b[0m\n",
      "\u001b[34m0%|          | 0/460749 [00:00<?, ?it/s]\u001b[0m\n",
      "\u001b[34m0%|          | 3/460749 [00:00<11:26:54, 11.18it/s]\u001b[0m\n",
      "\u001b[34m0%|          | 35/460749 [00:00<1:42:56, 74.59it/s]\u001b[0m\n",
      "\u001b[34m0%|          | 67/460749 [00:00<1:20:59, 94.80it/s]\u001b[0m\n",
      "\u001b[34m0%|          | 115/460749 [00:01<1:00:06, 127.73it/s]\u001b[0m\n",
      "\u001b[34m0%|          | 147/460749 [00:01<51:26, 149.22it/s]\u001b[0m\n",
      "\u001b[34m0%|          | 164/460749 [00:01<52:23, 146.51it/s]\u001b[0m\n",
      "\u001b[34m0%|          | 195/460749 [00:01<57:22, 133.77it/s]\u001b[0m\n",
      "\u001b[34m0%|          | 243/460749 [00:01<51:07, 150.15it/s]\u001b[0m\n",
      "\u001b[34m0%|          | 291/460749 [00:02<48:01, 159.79it/s]\u001b[0m\n",
      "\u001b[34m0%|          | 339/460749 [00:02<40:58, 187.29it/s]\u001b[0m\n",
      "\u001b[34m0%|          | 403/460749 [00:02<41:59, 182.71it/s]\u001b[0m\n",
      "\u001b[34m0%|          | 451/460749 [00:02<40:10, 190.96it/s]\u001b[0m\n",
      "\u001b[34m0%|          | 515/460749 [00:03<39:13, 195.53it/s]\u001b[0m\n",
      "\u001b[34m0%|          | 579/460749 [00:03<36:50, 208.20it/s]\u001b[0m\n",
      "\u001b[34m0%|          | 643/460749 [00:03<35:20, 217.01it/s]\u001b[0m\n",
      "\u001b[34m0%|          | 707/460749 [00:04<34:21, 223.19it/s]\u001b[0m\n",
      "\u001b[34m0%|          | 787/460749 [00:04<31:16, 245.14it/s]\u001b[0m\n",
      "\u001b[34m0%|          | 867/460749 [00:04<29:23, 260.71it/s]\u001b[0m\n",
      "\u001b[34m0%|          | 947/460749 [00:04<28:13, 271.58it/s]\u001b[0m\n",
      "\u001b[34m0%|          | 1027/460749 [00:05<27:25, 279.45it/s]\u001b[0m\n",
      "\u001b[34m0%|          | 1123/460749 [00:05<23:56, 320.05it/s]\u001b[0m\n",
      "\u001b[34m0%|          | 1235/460749 [00:05<23:08, 330.87it/s]\u001b[0m\n",
      "\u001b[34m0%|          | 1363/460749 [00:05<20:29, 373.64it/s]\u001b[0m\n",
      "\u001b[34m0%|          | 1507/460749 [00:06<18:10, 420.99it/s]\u001b[0m\n",
      "\u001b[34m0%|          | 1651/460749 [00:06<16:48, 455.38it/s]\u001b[0m\n",
      "\u001b[34m0%|          | 1811/460749 [00:06<15:23, 496.87it/s]\u001b[0m\n",
      "\u001b[34m0%|          | 2003/460749 [00:07<13:37, 561.03it/s]\u001b[0m\n",
      "\u001b[34m0%|          | 2195/460749 [00:07<12:36, 606.38it/s]\u001b[0m\n",
      "\u001b[34m1%|          | 2419/460749 [00:07<11:20, 673.85it/s]\u001b[0m\n",
      "\u001b[34m1%|          | 2675/460749 [00:07<10:05, 756.08it/s]\u001b[0m\n",
      "\u001b[34m1%|          | 2947/460749 [00:08<09:10, 832.07it/s]\u001b[0m\n",
      "\u001b[34m1%|          | 3235/460749 [00:08<08:26, 903.68it/s]\u001b[0m\n",
      "\u001b[34m1%|          | 3555/460749 [00:08<07:42, 989.06it/s]\u001b[0m\n",
      "\u001b[34m1%|          | 3923/460749 [00:08<06:55, 1100.63it/s]\u001b[0m\n",
      "\u001b[34m1%|          | 4307/460749 [00:09<06:21, 1197.78it/s]\u001b[0m\n",
      "\u001b[34m1%|          | 4723/460749 [00:09<05:49, 1302.98it/s]\u001b[0m\n",
      "\u001b[34m1%|          | 5187/460749 [00:09<05:19, 1426.62it/s]\u001b[0m\n",
      "\u001b[34m1%|          | 5683/460749 [00:09<04:53, 1552.43it/s]\u001b[0m\n",
      "\u001b[34m1%|▏         | 6227/460749 [00:10<04:28, 1690.29it/s]\u001b[0m\n",
      "\u001b[34m1%|▏         | 6803/460749 [00:10<04:09, 1819.70it/s]\u001b[0m\n",
      "\u001b[34m2%|▏         | 7427/460749 [00:10<03:50, 1968.96it/s]\u001b[0m\n",
      "\u001b[34m2%|▏         | 8115/460749 [00:11<03:31, 2142.61it/s]\u001b[0m\n",
      "\u001b[34m2%|▏         | 8835/460749 [00:11<03:16, 2303.30it/s]\u001b[0m\n",
      "\u001b[34m2%|▏         | 9619/460749 [00:11<03:01, 2485.68it/s]\u001b[0m\n",
      "\u001b[34m2%|▏         | 10451/460749 [00:11<02:48, 2666.52it/s]\u001b[0m\n",
      "\u001b[34m2%|▏         | 11347/460749 [00:12<02:36, 2864.88it/s]\u001b[0m\n",
      "\u001b[34m3%|▎         | 12307/460749 [00:12<02:25, 3074.51it/s]\u001b[0m\n",
      "\u001b[34m3%|▎         | 13331/460749 [00:12<02:15, 3292.15it/s]\u001b[0m\n",
      "\u001b[34m3%|▎         | 14435/460749 [00:12<02:06, 3530.85it/s]\u001b[0m\n",
      "\u001b[34m3%|▎         | 15587/460749 [00:13<01:41, 4397.69it/s]\u001b[0m\n",
      "\u001b[34m3%|▎         | 16085/460749 [00:13<01:45, 4218.03it/s]\u001b[0m\n",
      "\u001b[34m4%|▎         | 16835/460749 [00:13<01:58, 3743.29it/s]\u001b[0m\n",
      "\u001b[34m4%|▍         | 18147/460749 [00:13<01:46, 4138.58it/s]\u001b[0m\n",
      "\u001b[34m4%|▍         | 19539/460749 [00:13<01:22, 5326.91it/s]\u001b[0m\n",
      "\u001b[34m4%|▍         | 20141/460749 [00:14<01:26, 5065.48it/s]\u001b[0m\n",
      "\u001b[34m5%|▍         | 21027/460749 [00:14<01:38, 4474.43it/s]\u001b[0m\n",
      "\u001b[34m5%|▍         | 22579/460749 [00:14<01:13, 5961.69it/s]\u001b[0m\n",
      "\u001b[34m5%|▌         | 23254/460749 [00:14<01:17, 5657.49it/s]\u001b[0m\n",
      "\u001b[34m5%|▌         | 24243/460749 [00:14<01:10, 6171.16it/s]\u001b[0m\n",
      "\u001b[34m5%|▌         | 24908/460749 [00:14<01:15, 5759.23it/s]\u001b[0m\n",
      "\u001b[34m6%|▌         | 26003/460749 [00:15<01:24, 5130.96it/s]\u001b[0m\n",
      "\u001b[34m6%|▌         | 27859/460749 [00:15<01:14, 5804.16it/s]\u001b[0m\n",
      "\u001b[34m6%|▋         | 29811/460749 [00:15<00:56, 7622.81it/s]\u001b[0m\n",
      "\u001b[34m7%|▋         | 30648/460749 [00:15<01:00, 7091.76it/s]\u001b[0m\n",
      "\u001b[34m7%|▋         | 31859/460749 [00:15<00:55, 7791.92it/s]\u001b[0m\n",
      "\u001b[34m7%|▋         | 32693/460749 [00:15<00:59, 7134.64it/s]\u001b[0m\n",
      "\u001b[34m7%|▋         | 34035/460749 [00:16<01:06, 6412.80it/s]\u001b[0m\n",
      "\u001b[34m8%|▊         | 36323/460749 [00:16<00:58, 7206.40it/s]\u001b[0m\n",
      "\u001b[34m8%|▊         | 38691/460749 [00:16<00:54, 7767.55it/s]\u001b[0m\n",
      "\u001b[34m9%|▉         | 41203/460749 [00:16<00:50, 8290.07it/s]\u001b[0m\n",
      "\u001b[34m10%|▉         | 43827/460749 [00:17<00:39, 10435.50it/s]\u001b[0m\n",
      "\u001b[34m10%|▉         | 44983/460749 [00:17<00:42, 9748.13it/s]\u001b[0m\n",
      "\u001b[34m10%|█         | 46595/460749 [00:17<00:39, 10601.47it/s]\u001b[0m\n",
      "\u001b[34m10%|█         | 47737/460749 [00:17<00:42, 9630.48it/s]\u001b[0m\n",
      "\u001b[34m11%|█         | 49475/460749 [00:17<00:37, 10974.93it/s]\u001b[0m\n",
      "\u001b[34m11%|█         | 50657/460749 [00:17<00:43, 9324.55it/s]\u001b[0m\n",
      "\u001b[34m11%|█▏        | 52467/460749 [00:18<00:45, 8994.60it/s]\u001b[0m\n",
      "\u001b[34m12%|█▏        | 54707/460749 [00:18<00:34, 11602.57it/s]\u001b[0m\n",
      "\u001b[34m12%|█▏        | 56053/460749 [00:18<00:39, 10121.12it/s]\u001b[0m\n",
      "\u001b[34m12%|█▏        | 57395/460749 [00:18<00:38, 10369.85it/s]\u001b[0m\n",
      "\u001b[34m13%|█▎        | 58542/460749 [00:18<00:41, 9754.28it/s]\u001b[0m\n",
      "\u001b[34m13%|█▎        | 60035/460749 [00:18<00:39, 10244.14it/s]\u001b[0m\n",
      "\u001b[34m13%|█▎        | 61116/460749 [00:18<00:42, 9512.63it/s]\u001b[0m\n",
      "\u001b[34m14%|█▎        | 62547/460749 [00:19<00:40, 9927.81it/s]\u001b[0m\n",
      "\u001b[34m14%|█▍        | 63569/460749 [00:19<00:43, 9195.45it/s]\u001b[0m\n",
      "\u001b[34m14%|█▍        | 65443/460749 [00:19<00:37, 10623.54it/s]\u001b[0m\n",
      "\u001b[34m14%|█▍        | 66523/460749 [00:19<00:40, 9623.42it/s]\u001b[0m\n",
      "\u001b[34m15%|█▍        | 68387/460749 [00:19<00:35, 11116.20it/s]\u001b[0m\n",
      "\u001b[34m15%|█▌        | 69523/460749 [00:19<00:39, 10025.58it/s]\u001b[0m\n",
      "\u001b[34m15%|█▌        | 71219/460749 [00:19<00:35, 11092.89it/s]\u001b[0m\n",
      "\u001b[34m16%|█▌        | 72355/460749 [00:19<00:38, 10010.99it/s]\u001b[0m\n",
      "\u001b[34m16%|█▌        | 73843/460749 [00:20<00:36, 10605.37it/s]\u001b[0m\n",
      "\u001b[34m16%|█▋        | 74927/460749 [00:20<00:39, 9795.33it/s]\u001b[0m\n",
      "\u001b[34m17%|█▋        | 76451/460749 [00:20<00:37, 10253.43it/s]\u001b[0m\n",
      "\u001b[34m17%|█▋        | 77489/460749 [00:20<00:40, 9511.20it/s]\u001b[0m\n",
      "\u001b[34m17%|█▋        | 79251/460749 [00:20<00:36, 10562.63it/s]\u001b[0m\n",
      "\u001b[34m17%|█▋        | 80313/460749 [00:20<00:39, 9672.06it/s]\u001b[0m\n",
      "\u001b[34m18%|█▊        | 82147/460749 [00:20<00:34, 10950.00it/s]\u001b[0m\n",
      "\u001b[34m18%|█▊        | 83250/460749 [00:21<00:37, 9970.40it/s]\u001b[0m\n",
      "\u001b[34m18%|█▊        | 84979/460749 [00:21<00:34, 10991.25it/s]\u001b[0m\n",
      "\u001b[34m19%|█▊        | 86089/460749 [00:21<00:38, 9816.79it/s]\u001b[0m\n",
      "\u001b[34m19%|█▉        | 87699/460749 [00:21<00:34, 10816.77it/s]\u001b[0m\n",
      "\u001b[34m19%|█▉        | 88805/460749 [00:21<00:37, 9967.05it/s]\u001b[0m\n",
      "\u001b[34m20%|█▉        | 90483/460749 [00:21<00:34, 10775.45it/s]\u001b[0m\n",
      "\u001b[34m20%|█▉        | 91575/460749 [00:21<00:37, 9866.90it/s]\u001b[0m\n",
      "\u001b[34m20%|██        | 93219/460749 [00:21<00:34, 10681.57it/s]\u001b[0m\n",
      "\u001b[34m20%|██        | 94299/460749 [00:22<00:37, 9703.28it/s]\u001b[0m\n",
      "\u001b[34m21%|██        | 96019/460749 [00:22<00:33, 10797.41it/s]\u001b[0m\n",
      "\u001b[34m21%|██        | 97113/460749 [00:22<00:37, 9763.90it/s]\u001b[0m\n",
      "\u001b[34m21%|██▏       | 98787/460749 [00:22<00:33, 10809.48it/s]\u001b[0m\n",
      "\u001b[34m22%|██▏       | 99887/460749 [00:22<00:37, 9696.15it/s]\u001b[0m\n",
      "\u001b[34m22%|██▏       | 101587/460749 [00:22<00:32, 10905.78it/s]\u001b[0m\n",
      "\u001b[34m22%|██▏       | 102706/460749 [00:22<00:35, 10074.54it/s]\u001b[0m\n",
      "\u001b[34m23%|██▎       | 104268/460749 [00:23<00:31, 11419.67it/s]\u001b[0m\n",
      "\u001b[34m23%|██▎       | 105457/460749 [00:23<00:36, 9744.46it/s]\u001b[0m\n",
      "\u001b[34m23%|██▎       | 107139/460749 [00:23<00:33, 10649.45it/s]\u001b[0m\n",
      "\u001b[34m23%|██▎       | 108254/460749 [00:23<00:36, 9768.29it/s]\u001b[0m\n",
      "\u001b[34m24%|██▍       | 109891/460749 [00:23<00:32, 10659.29it/s]\u001b[0m\n",
      "\u001b[34m24%|██▍       | 110989/460749 [00:23<00:35, 9753.44it/s]\u001b[0m\n",
      "\u001b[34m24%|██▍       | 112723/460749 [00:23<00:32, 10849.50it/s]\u001b[0m\n",
      "\u001b[34m25%|██▍       | 113832/460749 [00:23<00:34, 9931.23it/s]\u001b[0m\n",
      "\u001b[34m25%|██▌       | 115603/460749 [00:24<00:31, 10969.74it/s]\u001b[0m\n",
      "\u001b[34m25%|██▌       | 116717/460749 [00:24<00:34, 9916.32it/s]\u001b[0m\n",
      "\u001b[34m26%|██▌       | 118467/460749 [00:24<00:30, 11086.54it/s]\u001b[0m\n",
      "\u001b[34m26%|██▌       | 119597/460749 [00:24<00:34, 9992.25it/s]\u001b[0m\n",
      "\u001b[34m26%|██▋       | 121187/460749 [00:24<00:31, 10830.43it/s]\u001b[0m\n",
      "\u001b[34m27%|██▋       | 122293/460749 [00:24<00:34, 9732.26it/s]\u001b[0m\n",
      "\u001b[34m27%|██▋       | 123795/460749 [00:24<00:32, 10479.54it/s]\u001b[0m\n",
      "\u001b[34m27%|██▋       | 124868/460749 [00:25<00:34, 9626.32it/s]\u001b[0m\n",
      "\u001b[34m27%|██▋       | 126611/460749 [00:25<00:31, 10719.45it/s]\u001b[0m\n",
      "\u001b[34m28%|██▊       | 127700/460749 [00:25<00:34, 9790.50it/s]\u001b[0m\n",
      "\u001b[34m28%|██▊       | 129507/460749 [00:25<00:30, 11023.00it/s]\u001b[0m\n",
      "\u001b[34m28%|██▊       | 130625/460749 [00:25<00:33, 9996.07it/s]\u001b[0m\n",
      "\u001b[34m29%|██▊       | 132243/460749 [00:25<00:30, 10812.40it/s]\u001b[0m\n",
      "\u001b[34m29%|██▉       | 133341/460749 [00:25<00:33, 9687.64it/s]\u001b[0m\n",
      "\u001b[34m29%|██▉       | 134963/460749 [00:26<00:30, 10736.11it/s]\u001b[0m\n",
      "\u001b[34m30%|██▉       | 136062/460749 [00:26<00:32, 9869.37it/s]\u001b[0m\n",
      "\u001b[34m30%|██▉       | 137875/460749 [00:26<00:29, 11037.72it/s]\u001b[0m\n",
      "\u001b[34m30%|███       | 138995/460749 [00:26<00:31, 10090.56it/s]\u001b[0m\n",
      "\u001b[34m31%|███       | 140787/460749 [00:26<00:28, 11183.84it/s]\u001b[0m\n",
      "\u001b[34m31%|███       | 141920/460749 [00:26<00:31, 10053.24it/s]\u001b[0m\n",
      "\u001b[34m31%|███       | 143587/460749 [00:26<00:28, 11059.90it/s]\u001b[0m\n",
      "\u001b[34m31%|███▏      | 144715/460749 [00:26<00:31, 9911.47it/s]\u001b[0m\n",
      "\u001b[34m32%|███▏      | 146211/460749 [00:27<00:29, 10560.95it/s]\u001b[0m\n",
      "\u001b[34m32%|███▏      | 147291/460749 [00:27<00:31, 9801.12it/s]\u001b[0m\n",
      "\u001b[34m32%|███▏      | 149139/460749 [00:27<00:28, 10965.19it/s]\u001b[0m\n",
      "\u001b[34m33%|███▎      | 150246/460749 [00:27<00:30, 10045.86it/s]\u001b[0m\n",
      "\u001b[34m33%|███▎      | 152083/460749 [00:27<00:27, 11227.69it/s]\u001b[0m\n",
      "\u001b[34m33%|███▎      | 153216/460749 [00:27<00:30, 10111.44it/s]\u001b[0m\n",
      "\u001b[34m34%|███▎      | 154963/460749 [00:27<00:27, 11247.93it/s]\u001b[0m\n",
      "\u001b[34m34%|███▍      | 156107/460749 [00:28<00:30, 10085.58it/s]\u001b[0m\n",
      "\u001b[34m34%|███▍      | 157571/460749 [00:28<00:28, 10623.75it/s]\u001b[0m\n",
      "\u001b[34m34%|███▍      | 158655/460749 [00:28<00:30, 9813.13it/s]\u001b[0m\n",
      "\u001b[34m35%|███▍      | 160387/460749 [00:28<00:27, 10765.21it/s]\u001b[0m\n",
      "\u001b[34m35%|███▌      | 161475/460749 [00:28<00:30, 9882.00it/s]\u001b[0m\n",
      "\u001b[34m35%|███▌      | 163235/460749 [00:28<00:27, 10914.55it/s]\u001b[0m\n",
      "\u001b[34m36%|███▌      | 164336/460749 [00:28<00:29, 10013.93it/s]\u001b[0m\n",
      "\u001b[34m36%|███▌      | 165987/460749 [00:28<00:27, 10774.26it/s]\u001b[0m\n",
      "\u001b[34m36%|███▋      | 167072/460749 [00:29<00:30, 9761.73it/s]\u001b[0m\n",
      "\u001b[34m37%|███▋      | 168739/460749 [00:29<00:27, 10749.43it/s]\u001b[0m\n",
      "\u001b[34m37%|███▋      | 169827/460749 [00:29<00:29, 9790.01it/s]\u001b[0m\n",
      "\u001b[34m37%|███▋      | 171331/460749 [00:29<00:28, 10329.75it/s]\u001b[0m\n",
      "\u001b[34m37%|███▋      | 172376/460749 [00:29<00:30, 9573.87it/s]\u001b[0m\n",
      "\u001b[34m38%|███▊      | 174323/460749 [00:29<00:25, 11032.68it/s]\u001b[0m\n",
      "\u001b[34m38%|███▊      | 175431/460749 [00:29<00:28, 10035.13it/s]\u001b[0m\n",
      "\u001b[34m38%|███▊      | 177091/460749 [00:30<00:26, 10881.51it/s]\u001b[0m\n",
      "\u001b[34m39%|███▊      | 178188/460749 [00:30<00:28, 9901.62it/s]\u001b[0m\n",
      "\u001b[34m39%|███▉      | 179795/460749 [00:30<00:26, 10675.10it/s]\u001b[0m\n",
      "\u001b[34m39%|███▉      | 180874/460749 [00:30<00:28, 9763.30it/s]\u001b[0m\n",
      "\u001b[34m40%|███▉      | 182451/460749 [00:30<00:26, 10422.66it/s]\u001b[0m\n",
      "\u001b[34m40%|███▉      | 183502/460749 [00:30<00:28, 9615.72it/s]\u001b[0m\n",
      "\u001b[34m40%|████      | 185331/460749 [00:30<00:25, 10831.64it/s]\u001b[0m\n",
      "\u001b[34m40%|████      | 186420/460749 [00:31<00:27, 9863.23it/s]\u001b[0m\n",
      "\u001b[34m41%|████      | 188115/460749 [00:31<00:25, 10823.28it/s]\u001b[0m\n",
      "\u001b[34m41%|████      | 189207/460749 [00:31<00:27, 9842.73it/s]\u001b[0m\n",
      "\u001b[34m41%|████▏     | 190787/460749 [00:31<00:25, 10546.65it/s]\u001b[0m\n",
      "\u001b[34m42%|████▏     | 191852/460749 [00:31<00:27, 9682.31it/s]\u001b[0m\n",
      "\u001b[34m42%|████▏     | 193587/460749 [00:31<00:24, 10714.22it/s]\u001b[0m\n",
      "\u001b[34m42%|████▏     | 194667/460749 [00:31<00:27, 9700.62it/s]\u001b[0m\n",
      "\u001b[34m43%|████▎     | 196339/460749 [00:31<00:24, 10713.77it/s]\u001b[0m\n",
      "\u001b[34m43%|████▎     | 197425/460749 [00:32<00:26, 9772.67it/s]\u001b[0m\n",
      "\u001b[34m43%|████▎     | 199059/460749 [00:32<00:24, 10596.89it/s]\u001b[0m\n",
      "\u001b[34m43%|████▎     | 200131/460749 [00:32<00:26, 9698.50it/s]\u001b[0m\n",
      "\u001b[34m44%|████▍     | 201907/460749 [00:32<00:23, 10848.96it/s]\u001b[0m\n",
      "\u001b[34m44%|████▍     | 203003/460749 [00:32<00:26, 9776.74it/s]\u001b[0m\n",
      "\u001b[34m44%|████▍     | 204643/460749 [00:32<00:23, 10768.94it/s]\u001b[0m\n",
      "\u001b[34m45%|████▍     | 205739/460749 [00:32<00:26, 9799.38it/s]\u001b[0m\n",
      "\u001b[34m45%|████▍     | 207203/460749 [00:33<00:24, 10260.32it/s]\u001b[0m\n",
      "\u001b[34m45%|████▌     | 208244/460749 [00:33<00:26, 9480.42it/s]\u001b[0m\n",
      "\u001b[34m46%|████▌     | 210003/460749 [00:33<00:23, 10578.33it/s]\u001b[0m\n",
      "\u001b[34m46%|████▌     | 211069/460749 [00:33<00:25, 9655.04it/s]\u001b[0m\n",
      "\u001b[34m46%|████▌     | 212787/460749 [00:33<00:23, 10703.55it/s]\u001b[0m\n",
      "\u001b[34m46%|████▋     | 213867/460749 [00:33<00:25, 9824.35it/s]\u001b[0m\n",
      "\u001b[34m47%|████▋     | 215475/460749 [00:33<00:23, 10471.19it/s]\u001b[0m\n",
      "\u001b[34m47%|████▋     | 216529/460749 [00:34<00:33, 7202.51it/s]\u001b[0m\n",
      "\u001b[34m47%|████▋     | 218659/460749 [00:34<00:31, 7680.18it/s]\u001b[0m\n",
      "\u001b[34m48%|████▊     | 221059/460749 [00:34<00:29, 8127.71it/s]\u001b[0m\n",
      "\u001b[34m48%|████▊     | 223411/460749 [00:34<00:28, 8330.79it/s]\u001b[0m\n",
      "\u001b[34m49%|████▉     | 225779/460749 [00:35<00:27, 8485.37it/s]\u001b[0m\n",
      "\u001b[34m50%|████▉     | 228323/460749 [00:35<00:26, 8785.82it/s]\u001b[0m\n",
      "\u001b[34m50%|█████     | 231059/460749 [00:35<00:24, 9220.29it/s]\u001b[0m\n",
      "\u001b[34m51%|█████     | 233587/460749 [00:35<00:24, 9273.39it/s]\u001b[0m\n",
      "\u001b[34m51%|█████     | 236099/460749 [00:36<00:24, 9285.96it/s]\u001b[0m\n",
      "\u001b[34m52%|█████▏    | 238627/460749 [00:36<00:23, 9318.83it/s]\u001b[0m\n",
      "\u001b[34m52%|█████▏    | 241363/460749 [00:36<00:22, 9572.11it/s]\u001b[0m\n",
      "\u001b[34m53%|█████▎    | 243875/460749 [00:37<00:22, 9501.19it/s]\u001b[0m\n",
      "\u001b[34m53%|█████▎    | 246419/460749 [00:37<00:22, 9482.22it/s]\u001b[0m\n",
      "\u001b[34m54%|█████▍    | 249187/460749 [00:37<00:21, 9722.50it/s]\u001b[0m\n",
      "\u001b[34m55%|█████▍    | 251795/460749 [00:37<00:21, 9710.80it/s]\u001b[0m\n",
      "\u001b[34m55%|█████▌    | 254243/460749 [00:38<00:21, 9520.92it/s]\u001b[0m\n",
      "\u001b[34m56%|█████▌    | 256931/460749 [00:38<00:21, 9658.37it/s]\u001b[0m\n",
      "\u001b[34m56%|█████▋    | 259507/460749 [00:38<00:20, 9627.16it/s]\u001b[0m\n",
      "\u001b[34m57%|█████▋    | 262163/460749 [00:38<00:20, 9699.49it/s]\u001b[0m\n",
      "\u001b[34m57%|█████▋    | 264723/460749 [00:39<00:20, 9626.82it/s]\u001b[0m\n",
      "\u001b[34m58%|█████▊    | 267491/460749 [00:39<00:19, 9821.63it/s]\u001b[0m\n",
      "\u001b[34m59%|█████▊    | 270131/460749 [00:39<00:19, 9802.60it/s]\u001b[0m\n",
      "\u001b[34m59%|█████▉    | 272883/460749 [00:40<00:18, 9929.89it/s]\u001b[0m\n",
      "\u001b[34m60%|█████▉    | 275523/460749 [00:40<00:18, 9894.00it/s]\u001b[0m\n",
      "\u001b[34m60%|██████    | 278195/460749 [00:40<00:18, 9883.81it/s]\u001b[0m\n",
      "\u001b[34m61%|██████    | 280867/460749 [00:40<00:18, 9890.98it/s]\u001b[0m\n",
      "\u001b[34m62%|██████▏   | 283587/460749 [00:41<00:17, 9944.98it/s]\u001b[0m\n",
      "\u001b[34m62%|██████▏   | 286291/460749 [00:41<00:17, 9975.56it/s]\u001b[0m\n",
      "\u001b[34m63%|██████▎   | 289027/460749 [00:41<00:17, 10028.23it/s]\u001b[0m\n",
      "\u001b[34m63%|██████▎   | 291635/460749 [00:41<00:17, 9926.08it/s]\u001b[0m\n",
      "\u001b[34m64%|██████▍   | 294307/460749 [00:42<00:16, 9920.42it/s]\u001b[0m\n",
      "\u001b[34m64%|██████▍   | 296979/460749 [00:42<00:16, 9925.41it/s]\u001b[0m\n",
      "\u001b[34m65%|██████▌   | 299827/460749 [00:42<00:15, 10117.63it/s]\u001b[0m\n",
      "\u001b[34m66%|██████▌   | 302579/460749 [00:42<00:15, 10149.30it/s]\u001b[0m\n",
      "\u001b[34m66%|██████▌   | 305171/460749 [00:43<00:15, 9971.24it/s]\u001b[0m\n",
      "\u001b[34m67%|██████▋   | 308243/460749 [00:43<00:14, 10373.93it/s]\u001b[0m\n",
      "\u001b[34m68%|██████▊   | 311075/460749 [00:43<00:14, 10433.23it/s]\u001b[0m\n",
      "\u001b[34m68%|██████▊   | 313843/460749 [00:44<00:14, 10387.48it/s]\u001b[0m\n",
      "\u001b[34m69%|██████▊   | 316355/460749 [00:44<00:14, 10051.69it/s]\u001b[0m\n",
      "\u001b[34m69%|██████▉   | 319235/460749 [00:44<00:13, 10243.71it/s]\u001b[0m\n",
      "\u001b[34m70%|██████▉   | 322147/460749 [00:44<00:13, 10414.57it/s]\u001b[0m\n",
      "\u001b[34m71%|███████   | 324979/460749 [00:45<00:13, 10443.46it/s]\u001b[0m\n",
      "\u001b[34m71%|███████   | 327555/460749 [00:45<00:10, 12544.23it/s]\u001b[0m\n",
      "\u001b[34m71%|███████▏  | 329059/460749 [00:45<00:11, 11056.68it/s]\u001b[0m\n",
      "\u001b[34m72%|███████▏  | 330333/460749 [00:45<00:14, 9235.19it/s]\u001b[0m\n",
      "\u001b[34m72%|███████▏  | 333043/460749 [00:45<00:13, 9540.29it/s]\u001b[0m\n",
      "\u001b[34m73%|███████▎  | 336003/460749 [00:46<00:12, 10016.46it/s]\u001b[0m\n",
      "\u001b[34m74%|███████▎  | 338803/460749 [00:46<00:12, 10137.57it/s]\u001b[0m\n",
      "\u001b[34m74%|███████▍  | 341619/460749 [00:46<00:11, 10237.19it/s]\u001b[0m\n",
      "\u001b[34m75%|███████▍  | 344277/460749 [00:46<00:09, 12567.99it/s]\u001b[0m\n",
      "\u001b[34m75%|███████▌  | 345810/460749 [00:47<00:10, 11067.91it/s]\u001b[0m\n",
      "\u001b[34m75%|███████▌  | 347108/460749 [00:47<00:12, 9231.83it/s]\u001b[0m\n",
      "\u001b[34m76%|███████▌  | 349875/460749 [00:47<00:11, 9638.47it/s]\u001b[0m\n",
      "\u001b[34m77%|███████▋  | 352723/460749 [00:47<00:10, 9951.10it/s]\u001b[0m\n",
      "\u001b[34m77%|███████▋  | 355435/460749 [00:47<00:08, 12524.53it/s]\u001b[0m\n",
      "\u001b[34m77%|███████▋  | 356992/460749 [00:48<00:09, 11006.26it/s]\u001b[0m\n",
      "\u001b[34m78%|███████▊  | 358309/460749 [00:48<00:11, 9199.35it/s]\u001b[0m\n",
      "\u001b[34m78%|███████▊  | 361091/460749 [00:48<00:10, 9577.45it/s]\u001b[0m\n",
      "\u001b[34m79%|███████▉  | 363955/460749 [00:48<00:09, 9931.40it/s]\u001b[0m\n",
      "\u001b[34m80%|███████▉  | 366766/460749 [00:49<00:07, 12670.21it/s]\u001b[0m\n",
      "\u001b[34m80%|███████▉  | 368358/460749 [00:49<00:08, 11165.91it/s]\u001b[0m\n",
      "\u001b[34m80%|████████  | 369705/460749 [00:49<00:09, 9309.44it/s]\u001b[0m\n",
      "\u001b[34m81%|████████  | 372099/460749 [00:49<00:09, 9215.18it/s]\u001b[0m\n",
      "\u001b[34m81%|████████▏ | 374979/460749 [00:50<00:08, 9712.60it/s]\u001b[0m\n",
      "\u001b[34m82%|████████▏ | 377843/460749 [00:50<00:08, 10007.64it/s]\u001b[0m\n",
      "\u001b[34m83%|████████▎ | 380691/460749 [00:50<00:07, 10188.53it/s]\u001b[0m\n",
      "\u001b[34m83%|████████▎ | 383292/460749 [00:50<00:06, 12463.78it/s]\u001b[0m\n",
      "\u001b[34m84%|████████▎ | 384813/460749 [00:50<00:06, 11039.66it/s]\u001b[0m\n",
      "\u001b[34m84%|████████▍ | 386227/460749 [00:51<00:07, 9349.49it/s]\u001b[0m\n",
      "\u001b[34m84%|████████▍ | 388739/460749 [00:51<00:07, 9320.42it/s]\u001b[0m\n",
      "\u001b[34m85%|████████▌ | 391715/460749 [00:51<00:06, 9889.81it/s]\u001b[0m\n",
      "\u001b[34m86%|████████▌ | 394579/460749 [00:51<00:06, 10129.80it/s]\u001b[0m\n",
      "\u001b[34m86%|████████▌ | 397203/460749 [00:52<00:06, 9989.86it/s]\u001b[0m\n",
      "\u001b[34m87%|████████▋ | 400195/460749 [00:52<00:05, 10336.51it/s]\u001b[0m\n",
      "\u001b[34m87%|████████▋ | 403043/460749 [00:52<00:05, 10408.63it/s]\u001b[0m\n",
      "\u001b[34m88%|████████▊ | 405528/460749 [00:52<00:04, 12428.85it/s]\u001b[0m\n",
      "\u001b[34m88%|████████▊ | 407013/460749 [00:53<00:04, 11002.62it/s]\u001b[0m\n",
      "\u001b[34m89%|████████▊ | 408387/460749 [00:53<00:05, 9280.63it/s]\u001b[0m\n",
      "\u001b[34m89%|████████▉ | 411187/460749 [00:53<00:05, 9625.47it/s]\u001b[0m\n",
      "\u001b[34m90%|████████▉ | 414115/460749 [00:53<00:04, 10033.05it/s]\u001b[0m\n",
      "\u001b[34m91%|█████████ | 416995/460749 [00:54<00:04, 10241.26it/s]\u001b[0m\n",
      "\u001b[34m91%|█████████ | 419747/460749 [00:54<00:04, 10226.41it/s]\u001b[0m\n",
      "\u001b[34m92%|█████████▏| 422275/460749 [00:54<00:03, 9945.01it/s]\u001b[0m\n",
      "\u001b[34m92%|█████████▏| 425091/460749 [00:54<00:03, 10105.64it/s]\u001b[0m\n",
      "\u001b[34m93%|█████████▎| 427845/460749 [00:54<00:02, 12540.92it/s]\u001b[0m\n",
      "\u001b[34m93%|█████████▎| 429388/460749 [00:55<00:02, 11054.06it/s]\u001b[0m\n",
      "\u001b[34m94%|█████████▎| 430851/460749 [00:55<00:03, 9544.52it/s]\u001b[0m\n",
      "\u001b[34m94%|█████████▍| 433394/460749 [00:55<00:02, 12152.10it/s]\u001b[0m\n",
      "\u001b[34m94%|█████████▍| 434929/460749 [00:55<00:02, 10759.28it/s]\u001b[0m\n",
      "\u001b[34m95%|█████████▍| 436419/460749 [00:56<00:03, 6518.79it/s]\u001b[0m\n",
      "\u001b[34m95%|█████████▌| 439475/460749 [00:56<00:02, 7858.47it/s]\u001b[0m\n",
      "\u001b[34m96%|█████████▌| 441283/460749 [00:56<00:02, 7519.61it/s]\u001b[0m\n",
      "\u001b[34m96%|█████████▋| 443571/460749 [00:57<00:02, 7808.21it/s]\u001b[0m\n",
      "\u001b[34m97%|█████████▋| 445571/460749 [00:57<00:01, 7688.07it/s]\u001b[0m\n",
      "\u001b[34m97%|█████████▋| 447875/460749 [00:57<00:01, 7943.36it/s]\u001b[0m\n",
      "\u001b[34m98%|█████████▊| 450147/460749 [00:57<00:01, 8075.56it/s]\u001b[0m\n",
      "\u001b[34m98%|█████████▊| 452419/460749 [00:58<00:01, 8179.72it/s]\u001b[0m\n",
      "\u001b[34m99%|█████████▊| 454435/460749 [00:58<00:00, 7973.19it/s]\u001b[0m\n",
      "\u001b[34m99%|█████████▉| 456771/460749 [00:58<00:00, 8179.88it/s]\u001b[0m\n",
      "\u001b[34m100%|█████████▉| 458979/460749 [00:58<00:00, 8184.02it/s]\u001b[0m\n",
      "\u001b[34m100%|██████████| 460749/460749 [00:58<00:00, 7815.91it/s]\u001b[0m\n",
      "\u001b[34m0%|          | 0/1 [00:00<?, ?it/s]\u001b[0m\n",
      "\u001b[34m100%|██████████| 1/1 [00:00<00:00, 827.93it/s]\u001b[0m\n",
      "\u001b[34m0%|          | 0/183 [00:00<?, ?it/s]\u001b[0m\n",
      "\u001b[34m2%|▏         | 3/183 [00:00<00:15, 11.68it/s]\u001b[0m\n",
      "\u001b[34m10%|█         | 19/183 [00:00<00:06, 26.03it/s]\u001b[0m\n",
      "\u001b[34m19%|█▉        | 35/183 [00:01<00:03, 38.49it/s]\u001b[0m\n",
      "\u001b[34m28%|██▊       | 51/183 [00:01<00:02, 46.30it/s]\u001b[0m\n",
      "\u001b[34m37%|███▋      | 67/183 [00:01<00:02, 51.34it/s]\u001b[0m\n",
      "\u001b[34m45%|████▌     | 83/183 [00:01<00:01, 54.72it/s]\u001b[0m\n",
      "\u001b[34m54%|█████▍    | 99/183 [00:02<00:01, 56.99it/s]\u001b[0m\n",
      "\u001b[34m63%|██████▎   | 115/183 [00:02<00:01, 44.80it/s]\u001b[0m\n",
      "\u001b[34m72%|███████▏  | 131/183 [00:02<00:01, 49.14it/s]\u001b[0m\n",
      "\u001b[34m89%|████████▉ | 163/183 [00:03<00:00, 68.94it/s]\u001b[0m\n",
      "\u001b[34m98%|█████████▊| 179/183 [00:03<00:00, 67.06it/s]\u001b[0m\n",
      "\u001b[34m100%|██████████| 183/183 [00:03<00:00, 54.59it/s]\u001b[0m\n",
      "\u001b[34m0%|          | 0/1 [00:00<?, ?it/s]\u001b[0m\n",
      "\u001b[34m100%|██████████| 1/1 [00:00<00:00, 945.94it/s]\u001b[0m\n",
      "\u001b[34m0%|          | 0/1 [00:00<?, ?it/s]\u001b[0m\n",
      "\u001b[34m100%|██████████| 1/1 [00:00<00:00, 925.08it/s]\u001b[0m\n",
      "\u001b[34m<<<< load model from uie-base-en!!!\u001b[0m\n",
      "\u001b[34mW0909 03:55:26.517583    72 gpu_resources.cc:61] Please NOTE: device: 0, GPU Compute Capability: 7.0, Driver API Version: 11.6, Runtime API Version: 10.2\u001b[0m\n",
      "\u001b[34mW0909 03:55:26.542336    72 gpu_resources.cc:91] device: 0, cuDNN Version: 8.0.\u001b[0m\n",
      "\u001b[34m#033[32m[2022-09-09 03:55:31,043] [    INFO]#033[0m - We are using <class 'paddlenlp.transformers.ernie.tokenizer.ErnieTokenizer'> to load '/opt/ml/checkpoints/'.#033[0m\u001b[0m\n",
      "\u001b[34mTraceback (most recent call last):\n",
      "  File \"finetune.py\", line 200, in <module>\u001b[0m\n",
      "\u001b[34mdo_train()\n",
      "  File \"finetune.py\", line 63, in do_train\u001b[0m\n",
      "\u001b[34mtrain_ds = load_dataset(\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/paddlenlp/datasets/dataset.py\", line 196, in load_dataset\u001b[0m\n",
      "\u001b[34mreturn reader_instance.read(**custom_kwargs)\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/paddlenlp/datasets/dataset.py\", line 833, in read\u001b[0m\n",
      "\u001b[34mreturn MapDataset(list(examples))\n",
      "  File \"/opt/ml/code/utils.py\", line 147, in reader\u001b[0m\n",
      "\u001b[34mif result['start'] + 1 <= max_content_len < result[\u001b[0m\n",
      "\u001b[34mTypeError: string indices must be integers\u001b[0m\n",
      "\u001b[34m2022-09-09 03:55:31,635 sagemaker-training-toolkit INFO     Waiting for the process to finish and give a return code.\u001b[0m\n",
      "\u001b[34m2022-09-09 03:55:31,635 sagemaker-training-toolkit INFO     Done waiting for a return code. Received 1 from exiting process.\u001b[0m\n",
      "\u001b[34m2022-09-09 03:55:31,636 sagemaker-training-toolkit ERROR    Reporting training FAILURE\u001b[0m\n",
      "\u001b[34m2022-09-09 03:55:31,636 sagemaker-training-toolkit ERROR    ExecuteUserScriptError:\u001b[0m\n",
      "\u001b[34mExitCode 1\u001b[0m\n",
      "\u001b[34mErrorMessage \"TypeError: string indices must be integers\u001b[0m\n",
      "\u001b[34m\"\u001b[0m\n",
      "\u001b[34mCommand \"/opt/conda/bin/python finetune.py --batch_size 16 --dev_path /opt/ml/input/data/training/dev.txt --device gpu --learning_rate 1e-05 --logging_steps 10 --max_seq_len 512 --model uie-base --num_epochs 1 --save_dir /opt/ml/model --seed 1000 --train_path /opt/ml/input/data/training/train.txt --valid_steps 100\"\u001b[0m\n",
      "\u001b[34m2022-09-09 03:55:31,636 sagemaker-training-toolkit ERROR    Encountered exit_code 1\u001b[0m\n",
      "\n",
      "2022-09-09 03:55:52 Uploading - Uploading generated training model\n",
      "2022-09-09 03:55:52 Failed - Training job failed\n",
      "ProfilerReport-1662695125: NoIssuesFound\n"
     ]
    },
    {
     "ename": "UnexpectedStatusException",
     "evalue": "Error for Training job pytorch-training-2022-09-09-03-45-25-415: Failed. Reason: AlgorithmError: ExecuteUserScriptError:\nExitCode 1\nErrorMessage \"TypeError: string indices must be integers\n\"\nCommand \"/opt/conda/bin/python finetune.py --batch_size 16 --dev_path /opt/ml/input/data/training/dev.txt --device gpu --learning_rate 1e-05 --logging_steps 10 --max_seq_len 512 --model uie-base --num_epochs 1 --save_dir /opt/ml/model --seed 1000 --train_path /opt/ml/input/data/training/train.txt --valid_steps 100\", exit code: 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnexpectedStatusException\u001b[0m                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_16357/3342038170.py\u001b[0m in \u001b[0;36m<cell line: 34>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     32\u001b[0m                     checkpoint_local_path=\"/opt/ml/checkpoints\")\n\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/python3/lib/python3.8/site-packages/sagemaker/workflow/pipeline_context.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    246\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself_instance\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msagemaker_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    247\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 248\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mrun_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    249\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python3/lib/python3.8/site-packages/sagemaker/estimator.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, inputs, wait, logs, job_name, experiment_config)\u001b[0m\n\u001b[1;32m   1062\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjobs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlatest_training_job\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1063\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1064\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlatest_training_job\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1065\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1066\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_compilation_job_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python3/lib/python3.8/site-packages/sagemaker/estimator.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, logs)\u001b[0m\n\u001b[1;32m   2145\u001b[0m         \u001b[0;31m# If logs are requested, call logs_for_jobs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2146\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlogs\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m\"None\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2147\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msagemaker_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogs_for_job\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjob_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2148\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2149\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msagemaker_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait_for_job\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjob_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python3/lib/python3.8/site-packages/sagemaker/session.py\u001b[0m in \u001b[0;36mlogs_for_job\u001b[0;34m(self, job_name, wait, poll, log_type)\u001b[0m\n\u001b[1;32m   3852\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3853\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3854\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_job_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdescription\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"TrainingJobStatus\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3855\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mdot\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3856\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python3/lib/python3.8/site-packages/sagemaker/session.py\u001b[0m in \u001b[0;36m_check_job_status\u001b[0;34m(self, job, desc, status_key_name)\u001b[0m\n\u001b[1;32m   3390\u001b[0m                     \u001b[0mactual_status\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3391\u001b[0m                 )\n\u001b[0;32m-> 3392\u001b[0;31m             raise exceptions.UnexpectedStatusException(\n\u001b[0m\u001b[1;32m   3393\u001b[0m                 \u001b[0mmessage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3394\u001b[0m                 \u001b[0mallowed_statuses\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Completed\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Stopped\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mUnexpectedStatusException\u001b[0m: Error for Training job pytorch-training-2022-09-09-03-45-25-415: Failed. Reason: AlgorithmError: ExecuteUserScriptError:\nExitCode 1\nErrorMessage \"TypeError: string indices must be integers\n\"\nCommand \"/opt/conda/bin/python finetune.py --batch_size 16 --dev_path /opt/ml/input/data/training/dev.txt --device gpu --learning_rate 1e-05 --logging_steps 10 --max_seq_len 512 --model uie-base --num_epochs 1 --save_dir /opt/ml/model --seed 1000 --train_path /opt/ml/input/data/training/train.txt --valid_steps 100\", exit code: 1"
     ]
    }
   ],
   "source": [
    "from sagemaker.pytorch import PyTorch\n",
    "\n",
    "hyperparameters = {'train_path': '/opt/ml/input/data/training/train.txt', \n",
    "                   'dev_path': '/opt/ml/input/data/training/dev.txt', \n",
    "                   'save_dir': '/opt/ml/model', \n",
    "                   'learning_rate': 1e-5, \n",
    "                   'batch_size': 16, \n",
    "                   'max_seq_len':512, \n",
    "                   'num_epochs': 1, \n",
    "                   'model': 'uie-base',\n",
    "                   'seed': 1000,\n",
    "                   'logging_steps': 10,\n",
    "                   'valid_steps': 100,\n",
    "                   'device': 'gpu'}\n",
    "\n",
    "instance_type = 'ml.p3.2xlarge'  # 'ml.p3.2xlarge' or 'ml.p3.8xlarge' or ...\n",
    "\n",
    "#git_config = {'repo': 'https://github.com/whn09/paddlenlp_sagemaker.git', 'branch': 'main'}\n",
    "\n",
    "estimator = PyTorch(entry_point='finetune.py',\n",
    "                    source_dir='./',\n",
    "                           # git_config=git_config,\n",
    "                    role=role,\n",
    "                    hyperparameters=hyperparameters,\n",
    "                    framework_version='1.9.1',\n",
    "                    py_version='py38',\n",
    "                    script_mode=True,\n",
    "                    instance_count=1,  # 1 or 2 or ...\n",
    "                    instance_type=instance_type,\n",
    "                    # Parameters required to enable checkpointing\n",
    "                    checkpoint_s3_uri=uie_en_model_s3, #使用你自己用来保存/加载模型的s3桶地址, 注意桶需要在us-east-1\n",
    "                    checkpoint_local_path=\"/opt/ml/checkpoints\")\n",
    "\n",
    "estimator.fit(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_job_name = estimator.latest_training_job.name\n",
    "# training_job_name = 'xxx'\n",
    "print(training_job_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deploy the trained model to prepare for predictions\n",
    "\n",
    "The deploy() method creates an endpoint (in this case locally) which serves prediction requests in real-time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -rf model.tar.gz\n",
    "!rm -rf model_*\n",
    "!rm -rf inference.*\n",
    "!aws s3 cp s3://$bucket/$training_job_name/output/model.tar.gz .\n",
    "!tar -xvf model.tar.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cp inference.* model/\n",
    "!cp model/code/requirements_gpu.txt model/code/requirements.txt\n",
    "!cd model && tar -czvf ../model-inference-gpu.tar.gz *\n",
    "\n",
    "!aws s3 cp model-inference-gpu.tar.gz s3://$bucket/$training_job_name/output/model-inference-gpu.tar.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# instance_type = 'local'\n",
    "# instance_type = 'ml.m5.xlarge'\n",
    "instance_type = 'ml.g4dn.xlarge'\n",
    "\n",
    "# predictor = estimator.deploy(initial_instance_count=1, instance_type=instance_type)\n",
    "\n",
    "from sagemaker.pytorch.model import PyTorchModel\n",
    "\n",
    "pytorch_model = PyTorchModel(model_data='s3://{}/{}/output/model-inference-gpu.tar.gz'.format(bucket, training_job_name), role=role,\n",
    "                             entry_point='infer_gpu.py', framework_version='1.9.0', py_version='py38', model_server_workers=4)  # TODO [For GPU], model_server_workers=6\n",
    "\n",
    "predictor = pytorch_model.deploy(instance_type=instance_type, initial_instance_count=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # endpoint_name = 'pytorch-inference-2022-07-05-07-28-16-183'  # m5.2xlarge\n",
    "# # endpoint_name = 'pytorch-inference-2022-07-06-04-02-11-091'  # g4dn.xlarge, 6 threads\n",
    "# endpoint_name = 'pytorch-inference-2022-07-06-06-19-21-855'  # g4dn.xlarge, 4 threads\n",
    "# predictor = sagemaker.predictor.Predictor(endpoint_name=endpoint_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Invoking the endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.serializers import JSONSerializer\n",
    "from sagemaker.deserializers import JSONDeserializer\n",
    "\n",
    "predictor.serializer = JSONSerializer()\n",
    "predictor.deserializer = JSONDeserializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "texts = ['\"北京市海淀区人民法院\\n民事判决书\\n(199x)建初字第xxx号\\n原告：张三。\\n委托代理人李四，北京市 A律师事务所律师。\\n被告：B公司，法定代表人王五，开发公司总经理。\\n委托代理人赵六，北京市 C律师事务所律师。\"', \n",
    "         '原告赵六，2022年5月29日生\\n委托代理人孙七，深圳市C律师事务所律师。\\n被告周八，1990年7月28日出生\\n委托代理人吴九，山东D律师事务所律师']\n",
    "\n",
    "import time\n",
    "start = time.time()\n",
    "outputs = predictor.predict(texts)\n",
    "end = time.time()\n",
    "print('outputs: ', outputs)\n",
    "print('time:', end-start)\n",
    "\n",
    "# for i in range(1000):\n",
    "#     start = time.time()\n",
    "#     outputs = predictor.predict(texts)\n",
    "#     end = time.time()\n",
    "#     print('time:', end-start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clean-up\n",
    "\n",
    "Deleting the local endpoint when you're finished is important since you can only run one local endpoint at a time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# estimator.delete_endpoint()\n",
    "predictor.delete_endpoint()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "notice": "Copyright 2018 Amazon.com, Inc. or its affiliates. All Rights Reserved.  Licensed under the Apache License, Version 2.0 (the \"License\"). You may not use this file except in compliance with the License. A copy of the License is located at http://aws.amazon.com/apache2.0/ or in the \"license\" file accompanying this file. This file is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License."
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
